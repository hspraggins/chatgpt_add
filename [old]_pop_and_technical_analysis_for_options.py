# -*- coding: utf-8 -*-
"""[old] PoP_and_Technical_Analysis_for_Options.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T1C4zYvn5fZ79zk2TVI-FHh_-j8J1vsW
"""

""" [*** Older version for sharing with the general public ***]
    Program uses yFinance, other libraries, and general financial calculations
    to report on the Probability of Profit (PoP) from 0 - 100%. Theoretically,
    if the PoP is high enough then profit is "assured." Assurance is based on
    statistical models and past performance (which is never a true indicator
    of future performance lol). Still, this exercise is useful to help a
    human identify where they might want to "hunt" for option trades.

    The basis of the statistical model is two-fold:
    1. Monte Carlo simulations,
    2. Black-Scholes model

    variants of Monte Carlo simulations are used to price options, so it
    bodes well to use or prefer that model. I've included Black Scholes
    because it's recommended by the chatbots (but what do they know, right?)

    In any resolve, this applies solely to American options.

    Lastly, I completed outputting technical analysis
    (e.g., RSI, Bollinger Bands, etc.) on the underlying stock to further
    bolster analysis and help traders "hunt" for options.

    Special Note: Every brokerage house already provides this functionality
    in some form. Why then did I do this?
    I wanted to
        1. Return to coding -- being more technical is always positive
        2. Get my hands dirty / learn -- experience developer life up close
        3. Feel empowered by building my own customized and curated
              analysis - no brokerage house breaks down the ETF or Index
              holdings and lets you perform PoP analysis on them in 1 click.
        Yeah, if you select QQQ- you can either
            a/ Analyze the Nasdaq 100 (QQQ) options or
            b/ Analyze all 100 holdings within the Nasdaq 100 for potential
                  option trades. Wow!
"""
#!pip install -q icecream
#from icecream import ic

from google.colab import drive
from google.colab import auth

from scipy.stats import norm

import requests
from bs4 import BeautifulSoup
import os
import sys
from io import StringIO
import ssl

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import BatchHttpRequest
from oauth2client.client import GoogleCredentials
from openpyxl.utils import get_column_letter

auth.authenticate_user()

import gspread
from google.auth.exceptions import DefaultCredentialsError
from google.oauth2.service_account import Credentials


def mount_and_load_librares_classes():
    """ Mount / access Google Drive
        load classes
    """
    import importlib

    def install_package(package):
      try:
        importlib.import_module(package)
        #print(f'{package} is already installed.')
      except ImportError:
        print(f'{package} is not installed. Installing...')
        !pip install -q {package}  # Install the package quietly using pip
      return None

    package = "google-api-python-client"
    install_package(package)

    package = "yfinance"
    install_package(package)

    package = "yahoo_fin" # extended version of yfinance
    install_package(package)

    package = "pandas"
    install_package(package)

    package = "numpy"
    install_package(package)

    # debug
    #package = "morningstar_data"
    #install_package(package)

    package = "scipy"
    install_package(package)

    package = "QuantLib-Python"
    install_package(package)

    package = "pytz"
    install_package(package)

    package = "numba"
    install_package(package)

    package = "tabulate"
    install_package(package)

    package = "textwrap"
    install_package(package)

    if not os.path.ismount('/content/drive'):
        drive.mount('/content/drive') # only mount drive if it's not already mounted

    new_path = '/content/drive/My Drive/py_for_import'
    if new_path not in sys.path:
        sys.path.append(new_path)

    """
    from '/content/drive/My Drive/py_for_import/technical_analysis.py' import *
    print("Import technical analysis")
    #from technical_analysis import *
    """
    """
    from style_config import StyleConfig
    from option_analysis_config import OptionAnalysisConfig
    from message_tracking import MessageTracking
    from time_config import TimeConfig
    """

    return None

mount_and_load_librares_classes()

import pytz

import QuantLib as ql

import math
import matplotlib.pyplot as plt
import pandas as pd
from pandas import Series
from pandas import DataFrame

import numpy as np
from numba import njit

import time
from datetime import datetime, timedelta
import re

import yfinance as yf
from yahoo_fin import stock_info as si

from googleapiclient.http import MediaFileUpload

import textwrap

# debug
#import morningstar_data
#from morningstar_data.direct import get_investment_data

# global variables
REMOVE_FROM_ETF = ['COIN', 'SQ', 'TSLA', 'ROKU', 'AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'TSLA', 'AVGO']
NUM_WARNING_MESSAGES = 0 # count of unbounded IV records from American options calculations (not yfinance)
NUM_TOTAL_MESSAGES = 0 # will compare with NUM_WARNING_MESSAGES to determine how much of an issue we have
PRINT_HEADING = False # determines how printing to console looks in one scenario
THRESHOLD = 92 # used to filter out option trades that could print to console
DEBUG_COUNTER = 1 # debug

# ANSI escape sequences for text color and other formatting
#  I like colors ðŸ˜‚ðŸ˜‚ðŸ˜‚
RESET = '\033[0m'
GREEN = '\033[92m'
RED = '\033[91m'
BLUE = '\033[34m'
PURPLE = '\033[35m'
YELLOW = '\033[33m'
WHITE = '\033[97m'
BOLD = '\033[1m'
UNDERLINE = '\033[4m'

# for Google doc outputs...
# Define the color as an RGB dictionary where values are from 0 to 1
BLUE_COLOR = {'red': 0.0, 'green': 0.0, 'blue': 1.0}  # Pure blue
RED_COLOR = {'red': 1.0, 'green': 0.0, 'blue': 0.0}  # Pure red
GREEN_COLOR = {'red': 0.0, 'green': 1.0, 'blue': 0.0}  # Pure green

HIGH_IV = 80 # if an option's IV Rank >= 80 then it's considered expensive
LOW_IV = 20 # if an option's IV Rank <= 20 then it's considered cheap / inexpensive

RISK_FREE_INTEREST_RATE = 0.035 # risk free interest rate
DIVIDEND_YIELD = 0.02 # dividend yield
DISCOUNT_RATE = 0.1
TERMINAL_GROWTH_RATE = 0.02

# Create a timezone object for Pacific Time
PACIFIC_TZ = pytz.timezone('America/Los_Angeles')

# Get the current UTC time; Make it timezone-aware; Change to Pacific Time (PST)
PACIFIC_TZ = pytz.timezone('America/Los_Angeles')
UTC_TIME = datetime.now(pytz.utc)
CURRENT_TIME = UTC_TIME.astimezone(PACIFIC_TZ)
FORMATTED_TIME = CURRENT_TIME.strftime("%I:%M %p")
TODAY = CURRENT_TIME.date()

def format_date(date,chosen_format="%Y-%m-%d"):
    return date.strftime(chosen_format)

def parse_date(date_str):
    # Define possible date formats
    date_formats = ['%Y-%m-%d', '%d-%m-%Y', '%m-%d-%Y', '%b-%d-%Y', '%d-%b-%Y']

    for date_format in date_formats:
        try:
            # Use the datetime class directly, which is now directly available
            dt = datetime.strptime(date_str, date_format)
            return dt
        except ValueError:
            continue

    # If no format matches, raise an exception
    raise ValueError("Date format for '{}' is not supported. Supported formats are: {}".format(date_str, ", ".join(date_formats)))

def set_normal_text_font_size(service, doc_id, font_size, num_lines):
    """
    This function is not used. Instead, I updated the default font-size to 12

    Sets the font size for normal text in a Google Doc...
    AFTER the document has been FULLY populated

    Args:
        service (googleapiclient.discovery.Resource): The Google Docs API service.
        doc_id (str): The ID of the Google Docs document.
        font_size (int): The font size to set for normal text.
        num_lines (int): Total number of lines in the document.
    """
    requests = [
        {
            'updateTextStyle': {
                'range': {
                    'startIndex': 1,      # Adjust startIndex based on your document structure
                    'endIndex': num_lines + 1,  # Adjust endIndex based on the number of lines
                },
                'textStyle': {
                    'fontSize': {
                        'magnitude': font_size,
                        'unit': 'PT'
                    }
                },
                'fields': 'fontSize'
            }
        }
    ]

    result = service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()
    return result

def format_ql_date(date_str):
    """ Convert a date string into a QuantLib Date. """
    dt = parse_date(date_str)  # Parse using the custom flexible parser
    return ql.Date(dt.day, dt.month, dt.year)

def truncate_string(input_string, maximum_length=20):
    """ Truncate a string to maximum length,
        but will go accept the entire word
        if max_length is the middle of a word.
        e.g., input_string = "Taiwan Semiconductor Manufacturing Limited Inc"
              max_length = 20, so Manufacturing would be cut off.
              Instead, the output = "Taiwan Semiconductor"

      Examples
        Taiwan Semiconductor Manufacturing Inc
        Analog Devices
        Intel
    """
    # Find the next ending of any word where it would be cut off
    last_space_index = input_string.find(" ", maximum_length)
    if last_space_index != -1:
        # If a space is found, truncate the string at the space
        return input_string[:last_space_index]
    else:
        return input_string

def get_free_cash_flows(ticker):
    """
    Retrieves the free cash flows for a given stock ticker.

    Args:
        ticker (str): The stock ticker symbol.

    Returns:
        pandas.Series: A Series containing the free cash flows for the stock.
    """
    stock = yf.Ticker(ticker)
    cash_flow = stock.cashflow
    free_cash_flows = cash_flow.loc['Total Cash From Operating Activities'] - cash_flow.loc['Capital Expenditures']
    return free_cash_flows

def calculate_intrinsic_value(ticker, num_years=5):
    """
    Calculates the intrinsic value of a stock using the Discounted Cash Flow (DCF) model.

    Args:
        ticker (str): The stock ticker symbol.
        num_years (int, optional): The number of years to project future cash flows. Default is 5.

    Global(s):
        discount_rate (float): The discount rate to use for discounting future cash flows (e.g., WACC).
        terminal_growth_rate (float): The terminal growth rate for calculating the terminal value.

    Returns:
        float: The intrinsic value of the stock.
    """
    global DISCOUNT_RATE
    global TERMINAL_GROWTH_RATE

    # Retrieve free cash flows
    fcf = get_free_cash_flows(ticker)

    # Calculate the average growth rate of free cash flows
    fcf_growth_rate = fcf.pct_change().mean()

    # Project future free cash flows
    projected_fcfs = []
    last_fcf = fcf[-1]
    for year in range(1, num_years + 1):
        projected_fcf = last_fcf * (1 + fcf_growth_rate) ** year
        projected_fcfs.append(projected_fcf)

    # Discount future free cash flows to present value
    discounted_fcfs = [fcf / (1 + DISCOUNT_RATE) ** i for i, fcf in enumerate(projected_fcfs, 1)]

    # Calculate terminal value and discount it to present value
    terminal_value = projected_fcfs[-1] * (1 + TERMINAL_GROWTH_RATE) / (DISCOUNT_RATE - TERMINAL_GROWTH_RATE)
    discounted_terminal_value = terminal_value / (1 + DISCOUNT_RATE) ** num_years

    # Sum discounted future cash flows and terminal value to get intrinsic value
    intrinsic_value = sum(discounted_fcfs) + discounted_terminal_value
    return intrinsic_value

def analyze_stock(ticker, current_price):
    """
    Analyzes the stock to determine if it is undervalued, overvalued, or fairly valued.

    Args:
        ticker (str): The stock ticker symbol.
        current_price (float): the current price of the stock.

    Returns:
        str: 'undervalued', 'overvalued', or 'fairly valued' based on the intrinsic value analysis.

    """
    intrinsic_value = calculate_intrinsic_value(ticker)

    if intrinsic_value > current_price:
        if intrinsic_value - current_price > 0.15:
            return intrinsic_value, 'Highly Undervalued'
        else:
            return instrinsic_value, 'Undervalued'
    elif intrinsic_value < current_price:
        if current_price - intrinsic_value > 0.15:
            return intrinsic_value, 'Highly Overvalued'
        else:
            return instrinsic_value, 'Overvalued'
    else:
        return instrinsic_value, 'Fairly Valued'

def calculate_implied_volatility(option_type, market_price, current_price, strike_price, expiration_date):
    """
    Calculate the implied volatility of an American option using QuantLib.
    Arrghhh!! this is the first and only time I've wanted to be an European lol

    :param option_type: 'call' or 'put'
    :param market_price: The observed market price of the option
    :param current_price: Price of the underlying asset
    :param strike_price: Strike price of the option
    :param expiration_date: Maturity date of the option (in QuantLib Date format)
    :return: Implied volatility as a decimal

    # Example usage
    option_type='call',
    market_price=7.0,
    underlying_price=100,
    strike_price=100,
    maturity_date=ql.Date(15, 1, 2026)  # January 15, 2026)

    print("Implied Volatility:", volatility)
    """
    global NUM_TOTAL_MESSAGES
    global NUM_WARNING_MESSAGES
    global TODAY
    global DIVIDEND_YIELD
    global RISK_FREE_INTEREST_RATE

    # Use global var "today" for the date function
    todays_date = ql.Date(TODAY.day, TODAY.month, TODAY.year)

    # Set the QuantLib global evaluation date to ensure consistency
    ql.Settings.instance().evaluationDate = todays_date

    # Convert expiration_date from a string or other format to QuantLib.Date
    expiration_ql_date  = format_ql_date(expiration_date)

    # Create the necessary QuantLib objects
    calendar            = ql.UnitedStates(ql.UnitedStates.NYSE)
    day_count           = ql.Actual365Fixed()
    risk_free_ts        = ql.YieldTermStructureHandle(ql.FlatForward(0, calendar, ql.QuoteHandle(ql.SimpleQuote(RISK_FREE_INTEREST_RATE)), day_count, ql.Continuous))
    dividend_yield_ts   = ql.YieldTermStructureHandle(ql.FlatForward(0, calendar, ql.QuoteHandle(ql.SimpleQuote(DIVIDEND_YIELD)), day_count, ql.Continuous))
    spot_handle         = ql.QuoteHandle(ql.SimpleQuote(current_price))

    # Setup the Black-Scholes-Merton process
    bsm_process = ql.BlackScholesMertonProcess(spot_handle, dividend_yield_ts, risk_free_ts, ql.BlackVolTermStructureHandle(ql.BlackConstantVol(todays_date, calendar, 0.20, day_count)))

    # Setup the option type and exercise
    option_type_ql = ql.Option.Call if option_type.upper() == "CALL" else ql.Option.Put
    payoff = ql.PlainVanillaPayoff(option_type_ql, strike_price)
    exercise = ql.AmericanExercise(todays_date, expiration_ql_date)
    option = ql.VanillaOption(payoff, exercise)

    # Pricing engine
    option.setPricingEngine(ql.BinomialVanillaEngine(bsm_process, 'crr', 200))

    implied_vol = 0.0
    NUM_TOTAL_MESSAGES += 1

    # Implied volatility calculation with bounds
    try:
        # Set the bounds and initial guess for the implied volatility calculation
        min_vol = 0.0001  # Lower bound of volatility, very close to zero
        max_vol = 12.0     # Upper bound of volatility, reasonably high(er)... was "4" and I increased it to "12" to try to mitigate the unbounded errors.
                          # Real life example error {e} for max_vol = 4.0 --> "Error finding an implied volatility: root not bracketed: f[0.0001,4] -> [8.188827e+00,5.405893e+01]"
        implied_vol = option.impliedVolatility(market_price, bsm_process, 1e-6, 100, min_vol, max_vol)
        return implied_vol
    except RuntimeError as e:
        NUM_WARNING_MESSAGES += 1
        return implied_vol

def calculate_d1(current_price, strike, time_in_years, volatility):
    """ Calculates the d1 value used in the Black-Scholes model.

    Parameters:
        current_price (float): Current price of the underlying asset.
        strike (float): Strike price of the option.
        time_in_yrs (float): Time to expiration (in years).
        volatility (float): Volatility of the underlying asset (annualized).
    """
    global RISK_FREE_INTEREST_RATE

    return 0 if (volatility * np.sqrt(time_in_years)) == 0 else (np.log(current_price / strike) + (RISK_FREE_INTEREST_RATE + 0.5 * volatility ** 2) * time_in_years) / (volatility * np.sqrt(time_in_years))

def calculate_delta(d1, option_type, current_price):
    """
    Calculates the delta of an option contract.
        Parameters:
        d1 (float): d1 value used in the Black-Scholes model.
        option_type (str): 'call' or 'put'.
        current_price (float): Current price of the underlying asset.
    """
    if current_price == 0:
        return 0  # Prevent invalid calculations if current_price is zero

    option_type = option_type.upper()  # Convert input to uppercase

    if option_type == 'CALL':
        delta = norm.cdf(d1)
    elif option_type == 'PUT':
        delta = norm.cdf(d1) - 1
    else:
        raise ValueError("Invalid option type. Expected 'CALL' or 'PUT'.")

    return delta

def calculate_theta(d1, option_type, current_price, strike, time_in_yrs, volatility):
    """
    Calculates the theta of an option contract.

    Parameters:
        d1 (float): d1 value used in the Black-Scholes model.
        option_type (str): 'call' or 'put'.
        current_price (float): Current price of the underlying asset.
        strike (float): Strike price of the option.
        time_in_yrs (float): Time to expiration (in years).
        volatility (float): Volatility of the underlying asset (annualized).
    """
    global RISK_FREE_INTEREST_RATE

    if current_price == 0:
        return 0  # Prevent invalid calculations if current_price is zero

    d2 = d1 - volatility * np.sqrt(time_in_yrs)
    option_type = option_type.upper()  # Convert input to uppercase
    if option_type == 'CALL':
        # check for divide / 0
        if ((2 * np.sqrt(time_in_yrs)) - RISK_FREE_INTEREST_RATE * strike * np.exp(-RISK_FREE_INTEREST_RATE * time_in_yrs) * norm.cdf(d2)) == 0:
            theta = 0
        else:
            theta = -(current_price * norm.pdf(d1) * volatility) / (2 * np.sqrt(time_in_yrs)) - RISK_FREE_INTEREST_RATE * strike * np.exp(-RISK_FREE_INTEREST_RATE * time_in_yrs) * norm.cdf(d2)
    elif option_type == 'PUT':
        # check for divide / 0
        if ((2 * np.sqrt(time_in_yrs)) + RISK_FREE_INTEREST_RATE * strike * np.exp(-RISK_FREE_INTEREST_RATE * time_in_yrs) * norm.cdf(-d2)) == 0:
            theta = 0
        else:
            theta = -(current_price * norm.pdf(d1) * volatility) / (2 * np.sqrt(time_in_yrs)) + RISK_FREE_INTEREST_RATE * strike * np.exp(-RISK_FREE_INTEREST_RATE * time_in_yrs) * norm.cdf(-d2)
    else:
        raise ValueError("Invalid option type. Expected 'CALL' or 'PUT'.")
    return theta

def calculate_gamma(d1, current_price, time_in_yrs, volatility):
    """
    Calculates the gamma of an option contract.

    Parameters:
        d1 (float): d1 value used in the Black-Scholes model.
        current_price (float): Current price of the underlying asset.
        time_in_yrs (float): Time to expiration (in years).
        volatility (float): Volatility of the underlying asset (annualized).
    """

    if current_price == 0:
        return 0  # Avoid division by zero if stock price is zero

    # check for divide / 0
    return 0 if (current_price * volatility * np.sqrt(time_in_yrs)) == 0 else norm.pdf(d1) / (current_price * volatility * np.sqrt(time_in_yrs))

def calculate_vega(d1, current_price, time_in_yrs):
    """
    Calculates the vega of an option contract.

    Parameters:
        d1 (float): d1 value used in the Black-Scholes model.
        current_price (float): Current price of the underlying asset.
        strike (float): Strike price of the option.
        time_in_yrs (float): Time to expiration (in years).
    """
    vega = current_price * np.sqrt(time_in_yrs) * norm.pdf(d1)

    return vega

def black_scholes_probability_of_profit(d1, option_type, time_in_yrs, volatility):
    """
    Calculate the probability of profit for an option using the Black-Scholes model.

    Parameters:
        option_type (str): 'call' or 'put'.
        K (float): Strike price of the option.
        r (float): Risk-free interest rate (annualized).
        time_in_yrs (float): Time to expiration (in years).
        volatility (float): Volatility of the underlying asset (annualized).

    Returns:
        probability_of_profit (float): The probability of profit for the option trade.
    """
    # Generate random price movements
    d2 = d1 - volatility * np.sqrt(time_in_yrs)

    option_type = option_type.upper()  # Convert input to uppercase
    if option_type == 'CALL':
        probability_of_profit = norm.cdf(d2)
    elif option_type == 'PUT':
        probability_of_profit = norm.cdf(-d2)
    else:
        raise ValueError("Invalid option type. Please choose 'call' or 'put'.")

    return probability_of_profit * 100  # Convert to percentage

def monte_carlo_probability_of_profit_mc(option_type, strike_price, premium_paid, underlying_price, volatility, time_in_yrs, american, num_simulations):
    """
    Calculate the probability of profit for an option trade using Monte Carlo simulation.

    Parameters:
    option_type (str): 'call' or 'put'.
    strike_price (float): The strike price of the option.
    premium_paid (float): The premium paid for the option.
    underlying_price (float): The current price of the underlying asset.
    volatility (float): The volatility of the underlying asset (annualized).
    time_in_yrs (float): The number of days until the option expires => in yrs
    num_simulations (int): Number of simulations to run.
    american (bool): Whether the option is American style. Default is True.

    Returns:
    probability_of_profit (float): The probability of profit for the option trade.
    """
    global RISK_FREE_INTEREST_RATE

    # setup variables for future calculations
    option_type = option_type.upper()

    """ debug
    print(f"\noption type = {option_type}")
    print(f"strike = {strike_price}")
    print(f"option price = {premium_paid}")
    print(f"stock price = {underlying_price}")
    print(f"volatility = {volatility}")
    print(f"Time (in years) = {time_in_years}")
    print(f"[american option type?] = {american}")
    print(f"Risk Free Interest Rate = {RISK_FREE_INTEREST_RATE}")
    print(f"Number of Simulations to Run = {num_simulations}")
    print("\n")
    """

    n_steps = 100  # Number of time steps
    dt = time_in_yrs / n_steps  # Time step
    discount = math.exp(-RISK_FREE_INTEREST_RATE * dt)  # Discount factor
    # done with setup

    # Generate stock price paths
    stock_paths = np.zeros((num_simulations, n_steps + 1))
    stock_paths[:, 0] = underlying_price

    for i in range(1, n_steps + 1):
        rand = np.random.normal(0, 1, num_simulations)
        stock_paths[:, i] = stock_paths[:, i - 1] * np.exp((RISK_FREE_INTEREST_RATE - 0.5 * volatility ** 2) * dt + volatility * np.sqrt(dt) * rand)

    # Value the option along each path
    option_values = np.zeros((num_simulations, n_steps + 1))

    if option_type == "CALL":
        option_payoff = np.maximum(stock_paths[:, -1] - strike_price, 0) - premium_paid

    else:
        option_payoff = np.maximum(strike_price - stock_paths[:, -1], 0) - premium_paid

    option_values = np.zeros((num_simulations, n_steps + 1))
    option_values[:, -1] = option_payoff

    for i in range(n_steps - 1, -1, -1):
        if american:
            if option_type == "CALL":
                exercise_value = np.maximum(stock_paths[:, i] - strike_price, 0) - premium_paid
            else:
                exercise_value = np.maximum(strike_price - stock_paths[:, i], 0) - premium_paid
            # these two next lines are not used to determine PoP;
            # however, they could be used in the future to determine
            # benefit of exercising the option vs selling the contract
            hold_value = discount * option_values[:, i + 1]
            option_values[:, i] = np.maximum(exercise_value, hold_value)
        else:
            option_values[:, i] = discount * option_values[:, i + 1]

    if option_type == "CALL":
        profit_condition = (stock_paths[:, -1] - strike_price) > premium_paid
    else:
        profit_condition = (strike_price - stock_paths[:, -1]) > premium_paid

    probability_of_profit = np.mean(profit_condition) * 100

    return probability_of_profit


def geometric_brownian_motion(stock_price, volatility, time_in_yrs, n_steps, num_simulations=1000):
    """
    Generate Monte Carlo paths for the underlying asset price using
    the geometric Brownian motion model.

    Args:
        price (float): Initial asset price.
        volatility (float): Volatility of the asset.
        time_in_yrs (int): Time to expiration in years.
        n_steps or "number_of_steps_time" (int): Number of time steps for simulation.
        num_simulations (int): Number of Monte Carlo simulations. Usually 10% less than MC num_simulations to shorten the run time.

    Returns:
        np.ndarray: Array of simulated asset price paths.
    """
    global RISK_FREE_INTEREST_RATE

    dt = time_in_yrs / n_steps
    paths = np.zeros((num_simulations, n_steps + 1))
    paths[:, 0] = stock_price
    for counter in range(1, n_steps + 1):
        z = np.random.normal(size=num_simulations)
        paths[:, counter] = paths[:, counter - 1] * np.exp((RISK_FREE_INTEREST_RATE - 0.5 * volatility ** 2) * dt + volatility * np.sqrt(dt) * z)
    return paths

def monte_carlo_probability_of_profit_lsm(option_type, strike_price, premium_paid, underlying_price, volatility, time_in_yrs, american_style=True, num_simulations=1000):
    """
    Price an American option using the Least Squares Monte Carlo (LSM) method.

    Args:
        option_type (str): Type of option ('PUT' or 'CALL').
        strike_price (float): Strike price of the option.
        underlying_price (float): Initial price of stock.
        premium_paid (float): Premium paid for the option.
            Note: premium_paid is not used in the LSM method.
        volatility (float): Volatility of the asset.
        time_in_yrs (int): Time to expiration in years.
        number_of_steps_time (int): Number of time steps for simulation.
        num_simulations (int): Number of Monte Carlo simulations. Usually 10% less than MC num_simulations to shorten the run time.

    Returns:
        tuple: Estimated price of the American option and the probability of profit.
    """
    global RISK_FREE_INTEREST_RATE

    if american_style:
        # do nothing for now
        pass # placeholder for the future

    n_steps = 100  # Number of time steps
    dt = time_in_yrs / n_steps
    discount_factor = np.exp(-RISK_FREE_INTEREST_RATE * dt)
    paths = geometric_brownian_motion(underlying_price, volatility, time_in_yrs, n_steps, num_simulations)
    # I could've passed "dt" to geometric_brownian_motion instead of time_in_yrs
    # and having it do another calculation

    # Initialize option values and exercise decisions
    option_values = np.zeros((num_simulations, n_steps + 1))
    exercise_decisions = np.zeros((num_simulations, n_steps + 1))

    # Terminal payoff
    option_type = option_type.upper()
    if option_type == 'CALL':
        option_values[:, n_steps] = np.maximum(paths[:, n_steps] - strike_price, 0)
    else:
        option_values[:, n_steps] = np.maximum(strike_price - paths[:, n_steps], 0)

    # Work backwards in time
    for counter in range(n_steps - 1, -1, -1):
        regression_values = option_values[:, counter + 1]
        exercise_values = np.maximum(strike_price - paths[:, counter], 0) if option_type == 'PUT' else np.maximum(paths[:, counter] - strike_price, 0)
        continuation_values = option_values[:, counter + 1] * discount_factor

        # Least squares regression
        polynom_order = 3
        regressors = {}
        for i in range(polynom_order + 1):
            regressors[i] = paths[:, counter] ** i

        regressor_matrix = np.vstack([regressors[i] for i in range(polynom_order + 1)]).T
        regression_coeffs = np.linalg.lstsq(regressor_matrix, regression_values, rcond=None)[0]

        # Estimate continuation values
        continuation_values = np.polyval(regression_coeffs, paths[:, counter])

        # Exercise decision
        exercise_decisions[:, counter] = continuation_values < exercise_values

        # Option values
        option_values[:, counter] = np.where(exercise_decisions[:, counter], exercise_values, continuation_values)

    # Determine the probability of profit
    if option_type == 'CALL':
        profit_mask = paths[:, -1] > strike_price
    else:
        profit_mask = paths[:, -1] < strike_price

    probability_of_profit = np.mean(profit_mask) * 100

    return probability_of_profit

def create_document(service, title):
    """
    Creates a new Google Docs document with narrow margins and landscape orientation.

    Args:
        service (googleapiclient.discovery.Resource): The Google Docs API service.
        title (str): The title of the new document.

    Returns:
        str: The document ID of the created document.
    """
    # Create the document
    document = service.documents().create(body={'title': title}).execute()
    doc_id = document.get('documentId')

    # Define the margin settings (0.5 inches = 36 points)
    margin_in_points = 36
    requests = [
        {
            'updateDocumentStyle': {
                'documentStyle': {
                    'marginTop': {'magnitude': margin_in_points, 'unit': 'PT'},
                    'marginBottom': {'magnitude': margin_in_points, 'unit': 'PT'},
                    'marginLeft': {'magnitude': margin_in_points, 'unit': 'PT'},
                    'marginRight': {'magnitude': margin_in_points, 'unit': 'PT'},
                    'pageSize': {
                        'width': {'magnitude': 792, 'unit': 'PT'},  # 11 inches
                        'height': {'magnitude': 612, 'unit': 'PT'}  # 8.5 inches
                    }
                },
                'fields': 'marginTop,marginBottom,marginLeft,marginRight,pageSize'
            }
        }
    ]

    # Update the document with the margin settings and landscape orientation
    service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()

    return doc_id

def create_sheet(service, title):
    # Function to create a new Google Sheet and return its ID

    spreadsheet_body = {
        'properties': {
            'title': title
        }
    }
    spreadsheet = service.spreadsheets().create(body=spreadsheet_body).execute()
    return spreadsheet.get('spreadsheetId')  # Return the new spreadsheet ID

def move_file_to_folder(drive_service, file_id, folder_id):
    # Retrieve the existing parents to remove
    file = drive_service.files().get(fileId=file_id,
                                     fields='parents').execute()
    previous_parents = ",".join(file.get('parents'))
    # Move the file to the new folder
    file = drive_service.files().update(fileId=file_id,
                                        addParents=folder_id,
                                        removeParents=previous_parents,
                                        fields='id, parents').execute()

def update_or_create_sheet_with_size_and_format(service, spreadsheet_id, title, row_count, col_count):
    # Update or create a new worksheet with specified dimensions and formatting
    try:
        # Get the current list of all sheets in the spreadsheet
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        sheets = spreadsheet.get('sheets', [])
        sheet_properties = {sheet['properties']['title']: sheet['properties'] for sheet in sheets}

        # Check if sheet exists
        if title in sheet_properties:
            current_properties = sheet_properties[title]
            current_row_count = current_properties.get('gridProperties', {}).get('rowCount', 0)
            current_col_count = current_properties.get('gridProperties', {}).get('columnCount', 0)

            # Update existing sheet if its size is insufficient
            if current_row_count < row_count or current_col_count < col_count:
                body = {
                    'requests': [{
                        'updateSheetProperties': {
                            'properties': {
                                'sheetId': current_properties['sheetId'],
                                'gridProperties': {
                                    'rowCount': max(row_count, current_row_count),
                                    'columnCount': max(col_count, current_col_count)
                                }
                            },
                            'fields': 'gridProperties(rowCount,columnCount)'
                        }
                    }]
                }
                response = service.spreadsheets().batchUpdate(spreadsheetId=spreadsheet_id, body=body).execute()
                print(f"Updated '{title}' to {max(row_count, current_row_count)} rows and {max(col_count, current_col_count)} columns.")
            # else:
                # we already have a sheet with the appropriate columns and rows
                # print(f"'{title}' already exists with sufficient size.")
        else:
            # Create new sheet with specified dimensions
            body = {
                'requests': [{
                    'addSheet': {
                        'properties': {
                            'title': title,
                            'gridProperties': {
                                'rowCount': row_count,
                                'columnCount': col_count
                            }
                        }
                    }
                }]
            }
            response = service.spreadsheets().batchUpdate(spreadsheetId=spreadsheet_id, body=body).execute()
            print(f"Sheet '{title}' created with {row_count} rows and {col_count} columns.")

            # Refresh the sheet properties
            spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
            sheets = spreadsheet.get('sheets', [])
            sheet_properties = {sheet['properties']['title']: sheet['properties'] for sheet in sheets}
            current_properties = sheet_properties[title]

        # Set formatting for the sheet
        first_row_range = 'A1:Z1'  # Adjust the range as needed
        cell_properties = {'wrapStrategy': 'WRAP', 'textFormat': {'bold': True}}

        body = {
            'requests': [{
                'updateCells': {
                    'range': {
                        'sheetId': current_properties['sheetId'],
                        'startRowIndex': 0,
                        'endRowIndex': 1,
                        'startColumnIndex': 0,
                        'endColumnIndex': col_count
                    },
                    'rows': [
                        {
                            'values': [
                                {
                                    'userEnteredFormat': cell_properties
                                }
                            ] * col_count
                        }
                    ],
                    'fields': 'userEnteredFormat(wrapStrategy,textFormat)'
                }
            }]
        }
        service.spreadsheets().batchUpdate(spreadsheetId=spreadsheet_id, body=body).execute()

        # Set column widths - 28 columns
        """
            1. 'Company Name & Ticker': company_ticker,
            2. 'Contract Symbol':option_data.iloc[0]['contractSymbol'],
            3. 'Option Type': option_type,
            4. 'Strike Price': closest_strike,
            5. 'Days Until Expiration': expiration_in_days,
            6. 'Probability of Profit MC': probability_mc,
            7. 'Probability of Profit LSM': probability_lsm,
            8. 'Probability of Profit BSM': probability_bsm,
            9. 'Bid': f"${option_data.iloc[0]['bid']:.2f}",
            10. 'Ask': f"${option_data.iloc[0]['ask']:.2f}",
            11. 'Last Price': f"${option_data.iloc[0]['lastPrice']:.2f}",
            12. 'Breakeven Price (Range)': breakeven_price_range_print,
            13. 'Breakeven In the Money': breakeven_in_the_money,
            14. 'Underlying Stock Price': current_price_print,
            15. 'Volume': option_data.iloc[0]['volume'],
            16. 'Open Interest': option_data.iloc[0]['openInterest'],
            17. 'Delta': f"{delta:.2f}",
            18. 'Gamma': f"{gamma}%",
            19. 'Theta': f"{theta:.2f}",
            20. 'Vega': f"{vega:.2f}",
            21. 'In the Money': in_the_money,
            22. 'Implied Volatility (calculated)': f"{volatility:.2f}%",
            23. 'Implied Volatility II (yfinance)': f"{implied_volatility2:.2f}%",
            24. 'IV Rank (calculated)': iv_rank,
            25. 'IV Rank II (yfinance)': iv_rank2,
            26. 'Change': change_amount,
            27. 'Percent Change': change_percent_amount,
            28. 'Expiration Date': formatted_expiration_date
        """
        column_widths = [247, 182, 83, 83, 104, 108, 108,
                         108, 80, 80, 80, 138, 106, 108,
                         92, 90, 90, 90, 90, 90, 90,
                         114, 114, 138, 138, 92, 92, 92]
        for col, width in enumerate(column_widths, start=1):
            col_letter = get_column_letter(col)
            service.spreadsheets().values().update(
                spreadsheetId=spreadsheet_id,
                range=f"{title}!{col_letter}1",
                valueInputOption='USER_ENTERED',
                body={'values': [['']]}).execute()  # Write a blank value to trigger data update

            result = service.spreadsheets().values().get(
                spreadsheetId=spreadsheet_id,
                range=f"{title}!{col_letter}1"
            ).execute()

            if 'values' in result:
                cell = result['values'][0][0]
                service.spreadsheets().values().update(
                    spreadsheetId=spreadsheet_id,
                    range=f"{title}!{col_letter}1",
                    valueInputOption='USER_ENTERED',
                    body={'values': [[cell]]}).execute()  # Trigger update
            #else: # not necessary warning message
                #print(f"No values found in range {title}!{col_letter}1")

            service.spreadsheets().batchUpdate(
                spreadsheetId=spreadsheet_id,
                body={
                    'requests': [{
                        'updateDimensionProperties': {
                            'range': {
                                'sheetId': current_properties['sheetId'],
                                'dimension': 'COLUMNS',
                                'startIndex': col - 1,
                                'endIndex': col
                            },
                            'properties': {
                                'pixelSize': width
                            },
                            'fields': 'pixelSize'
                        }
                    }]
                }
            ).execute()

    except HttpError as error:
        # Handle API errors
        print(f"An API error occurred: {error}")
        return False

    return True

def retry_request(execute_func, attempts=5, delay=3):
    """
    Retries a given function up to a specified number of attempts if an ssl.SSLError occurs.

    Args:
    execute_func (callable): The function to execute.
    attempts (int): Maximum number of attempts.
    delay (int): Delay between attempts in seconds.

    Returns:
    Any: The return value of the execute_func() on success.

    Raises:
    Exception: Re-raises the ssl.SSLError or any other exception after the final attempt.
    """
    for attempt in range(attempts):
        try:
            return execute_func()
        except ssl.SSLError as e:
            print(f"SSL error on attempt {attempt+1}: {str(e)}")
            if attempt < attempts - 1:
                time.sleep(delay)  # Wait for the specified delay period before retrying
                continue
            else:
                raise  # Re-raises the last exception if all attempts fail
        except Exception as e:
            # Handle other exceptions that might occur
            print(f"Error on attempt {attempt+1}: {str(e)}")
            if attempt < attempts - 1:
                time.sleep(delay)
                continue
            else:
                raise

def clean_value(value):
    """Convert values to string, format datetime, and strip ANSI codes."""
    if isinstance(value, datetime):
        return value.strftime('%Y-%m-%d %H:%M:%S')  # Format datetime as string
    elif isinstance(value, str):
        return re.sub(r'\x1b\[.*?m', '', value)  # Remove ANSI escape sequences
    elif isinstance(value, (int)):
        return value  # Ensure numbers are sent as numbers, not strings
    elif isinstance(value, float) and math.isnan(value):
        return ""  # Replace NaN with an empty string or suitable placeholder
    elif isinstance(value, float):
        return value
    elif isinstance(value, bool):
        return value  # True or False as boolean values
    return str(value)  # Convert other types to string

def prepare_sheet_data(sorted_data):
    """
    Prepare multiple rows of data for Google Sheets, including a header row.
    """
    headers = list(sorted_data[0].keys()) if sorted_data else []
    sheet_data = [headers] + [prepare_row_data(item) for item in sorted_data]
    return sheet_data

def prepare_data_for_sheets(raw_data):
    """
    Assume raw_data is a list of dictionaries, convert each to row
    """
    cleaned_data = []
    for row in raw_data:
        cleaned_row = [clean_value(item) for item in row]
        cleaned_data.append(cleaned_row)
    return cleaned_data

def get_column_letter(col_index):
    if col_index <= 26:
        return chr(64 + col_index)
    else:
        return chr(64 + (col_index - 1) // 26) + chr(64 + ((col_index - 1) % 26) + 1)

def write_text_to_Google_sheet_in_chunks(service, spreadsheet_id, sheet_name, raw_data, num_columns, chunk_size=250):
    """
    Writes large data to Google Sheets in chunks to avoid timeouts and large payload errors.
    """
    prepared_data = prepare_data_for_sheets(raw_data)  # Clean and prepare data
    num_rows = len(prepared_data)

    # Determine the last column letter (assuming num_columns is provided correctly)
    last_column_letter = get_column_letter(num_columns)

    for i in range(0, num_rows, chunk_size):
        start_row = i + 1
        end_row = i + chunk_size
        if end_row > num_rows:
            end_row = num_rows

        current_range = f'{sheet_name}!A{start_row}:{last_column_letter}{end_row}'
        chunk = prepared_data[i:end_row]
        body = {'values': chunk}
        request = service.spreadsheets().values().update(
            spreadsheetId=spreadsheet_id,
            range=current_range,
            valueInputOption='USER_ENTERED',
            body=body
        )
        response = retry_request(request.execute)  # Use retry logic for the request execution

def clean_value(value):
    """Convert values to string, format datetime, and strip ANSI codes."""
    if isinstance(value, datetime):
        return value.strftime('%Y-%m-%d %H:%M:%S')  # Format datetime as string
    elif isinstance(value, str):
        return re.sub(r'\x1b\[.*?m', '', value)  # Remove ANSI escape sequences
    elif isinstance(value, (int)):
        return value  # Ensure numbers are sent as numbers, not strings
    elif isinstance(value, float) and math.isnan(value):
        return ""  # Replace NaN with an empty string or suitable placeholder
    elif isinstance(value, float):
        return value
    elif isinstance(value, bool):
        return value  # True or False as boolean values
    return str(value)  # Convert other types to string

def write_text_to_Google_doc(service, document_id, text, bold=False, color=None, page_break=False):
    """
    Inserts text into a Google Document and optionally applies formatting.

    This function inserts the provided text at the end of the specified Google Document.
    It can also apply bold formatting, color styling, and insert a page break after the text.

    Parameters:
        service (googleapiclient.discovery.Resource): The Google Docs API service instance.
        document_id (str): The ID of the Google Document.
        text (str): The text to insert into the document.
        bold (bool, optional): Whether to apply bold formatting to the text. Default is False.
        color (dict, optional): A dictionary with 'red', 'green', and 'blue' keys for text color. Default is None.
        page_break (bool, optional): Whether to insert a page break after the text. Default is False.

    Returns:
        int: The new end index of the document after inserting the text and applying formatting.

    Raises:
        googleapiclient.errors.HttpError: If the request to update the document fails.
    """
    # Clean the text to remove special characters
    text = clean_value(text)

    if isinstance(text, list):
        text = '\n'.join(text)

    if not text.strip():  # Ensure text is not empty or just whitespace
        text = "<blanks>"  # Try to fix it.

    # Fetch the current document to find the end of the document
    doc = service.documents().get(documentId=document_id).execute()
    doc_content = doc.get('body').get('content')

    # Determine the current end index of the document
    if doc_content and 'endIndex' in doc_content[-1]:
        end_index = doc_content[-1]['endIndex'] - 1
    else:
        end_index = 1  # Safe fallback if no valid content is found

    # Create the requests for inserting text and updating styles
    requests = [{
        'insertText': {
            'location': {
                'index': end_index,
            },
            'text': text
        }
    }]

    # Calculate new_end_index ensuring it is within valid bounds
    new_end_index = end_index + len(text)

    if bold:
        requests.append({
            'updateTextStyle': {
                'range': {
                    'startIndex': end_index,
                    'endIndex': new_end_index
                },
                'textStyle': {
                    'bold': True
                },
                'fields': 'bold'
            }
        })

    if color:
        requests.append({
            'updateTextStyle': {
                'range': {
                    'startIndex': end_index,
                    'endIndex': new_end_index
                },
                'textStyle': {
                    'foregroundColor': {
                        'color': {
                            'rgbColor': {
                                'red': color.get('red', 0.0),
                                'green': color.get('green', 0.0),
                                'blue': color.get('blue', 0.0)
                            }
                        }
                    }
                },
                'fields': 'foregroundColor'
            }
        })

    if page_break:
        requests.append({
            'insertPageBreak': {
                'location': {
                    'index': new_end_index
                }
            }
        })

    # Execute the batch update
    try:
        response = service.documents().batchUpdate(documentId=document_id, body={'requests': requests}).execute()
        return new_end_index
    except HttpError as error:
        print(f"An error occurred: {error}")
        print(f"Error details: {error.content}")
        raise

def prepare_row_data(row_data):
    """Prepare the row data for insertion into Google Sheets.
    Example usage
    (call_row or put_row) = {
        'Expiration Date': datetime(2024, 4, 26, 0, 0),
        'Days Until Expiration': 4,
        'Strike Price': 149.0,
        'Contract Symbol': 'AAPL240426C00149000',
        'Company & Ticker: 'Apple Inc (AAPL)',
        'Probability of Profit LSM': '\x1b[1m\x1b[4m\x1b[92m48.20%\x1b[0m',
        'Probability of Profit MC': '\x1b[1m\x1b[4m\x1b[92m96.60%\x1b[0m',
        'Probability of Profit BSM': '\x1b[1m\x1b[4m\x1b[92m96.60%\x1b[0m',
        'Last Price': 16.24,
        'Implied Volatility (calculated)': '52.83%',
        'Implied Volatility II (yfinance)': '0.00',
        'Bid': 15.95,
        'Ask': 16.45,
        'Last Price': $17.00,
        'Change': '\x1b[1m\x1b[91m-1.9099998\x1b[0m',
        'Percent Change': '\x1b[1m\x1b[91m-10.52%\x1b[0m',
        'Volume': 27.0,
        'Open Interest': 6,
        'In the Money': '\x1b[1m\x1b[92mTrue\x1b[0m',
        'IV Rank (calculated)': '\x1b[1m\x1b[92m15.81% INEXPENSIVE\x1b[0m'
        'IV Rank II (yfinance)': '0.00',
        'Underlying Stock Price': 16.24,
        'Breakeven Price (Range)': '0.00',
        'Option Type': 'CALL',
        'Delta': 0.503,
        'Gamma': 0.0019,
        'Theta': 0.1,
        'Vega': 0.0022
    }
    """
    return [clean_value(value) for value in row_data.values()]

def get_custom_ticker(): # original
    while True:
        user_ticker = input("Enter your custom ticker symbol: ").strip().upper()

        # Attempt to fetch data for the entered ticker symbol using yfinance
        ticker_info = yf.Ticker(user_ticker)
        #sector = ticker_info.info['sector'] # will be used as a prompt output- had to change this bc not every stock has a sector

        # Try fetching some basic info such as the sector, to check if the ticker is valid
        try:
            #sector = ticker_info.info['sector'] # will be used as a prompt output- had to change this bc not every stock has a sector
            hist = ticker_info.history(period="1mo")
            return user_ticker # ticker validated successfully
        except KeyError:
            # If 'history' or any other expected info is not found, it's likely not a valid ticker
            print(f"{user_ticker} does not appear to be a valid ticker symbol. Please try again.")

def UE_choose_stock_index_etf():
    """ user-entered (UE) stock index or ETF """

    options = ['Enter your own ticker symbol', '*MAGNIFICENT 7', '*TOP 31 BUZZ - Part I', '*TOP 31 BUZZ - Part II', '*TOP 31 BUZZ - All', 'ARKF', 'ARKK', 'BUZZ', 'DJIA', 'PPH', 'QQQ', 'SCHD', 'SMH', 'SPY', 'USD', 'XLC', 'XOP']
    print(f"\n\n{BOLD}Step 1 - Choose Your ETF/Stocks (Holdings) or Stock (Holding)... processing with filter on this threshold{RESET}\n")
    print("Choose the stock index or ETF you want to run on:")
    for index, option in enumerate(options, start=1):
        print(f"{index}. {option}")

    choice = input("Enter your choice (number): ")
    try:
        selected_index = int(choice) - 1
        selected = options[selected_index]
        print(f"You selected: {selected}")

        if selected == 'Enter your own ticker symbol':
            return get_custom_ticker(), True  # Return the custom ticker and True for user-entered
        else:
            return selected, False  # Return the selected option and False for not user-entered

    except (IndexError, ValueError):
        print("Invalid selection, please enter a number from the list.")
        return UE_choose_stock_index_etf()  # Recursively ask again

def UE_get_min_POP():
    """ user-entered (UE) minimum probability of profit """

    print(f"{BOLD}\nStep 3 - Choose Your Minimum Probability of Profit (PoP)... processing with filter on this threshold{RESET}\n")
    while True:
        try:
            user_input = float(input("Enter a value for the minimum Probability of Profit to filter on [between 0.00 and 100.00]: "))
            if 0.00 <= user_input <= 100.00:
                return user_input
            else:
                print("Invalid input. Please enter a value between 0.00 and 100.00.")
        except ValueError:
            print("Invalid input. Please enter a number.")

def UE_get_feedback_preference():
    """ user-entered decision whether to
    1. print out the graphs and technical analysis information.
        Printing graphs slows the program down and often halts the program (idk).
        If the user selects Yes then they want to see graphs and
        Technical analysis information in the output files.

    2. SOLELY print out the graphs and technical analysis information - no details

    3. print out records to console during long periods of processing.
        If the user selects Yes then they want to see output / feedback from the system during long processing times.
        Currently, the additional criteria to print is POP > 95% -- choosing a high mark of 95% ensures there isn't too much printing to screen.

    Returns
        process_graphs (bool) True = "Process and output graphs and technical analysis along with CALL/PUT details"
        process_the_details (bool) False = "Solely process the technical analysis without CALL/PUT details"
        print_samples (bool) True = "Print out sample records to console during long processing times"
    """
    global BOLD
    global RED

    print(f"{BOLD}\nStep 2 - Choose Your Processing & Reporting Preference... this {RED}does {RESET}{BOLD}affect final output{RESET}\n")
    process_the_details = True  # for now, "process_the_details" defaults to True
    options = ['Process & output technical analysis & graphs',
               'Skip processing technical analysis & graphs',
               'Solely process & output technical analysis & graphs, i.e., Skip processing the CALL/PUT details!']

    print("Choose the option you want to run on:")
    for index, option in enumerate(options, start=1):
        print(f"{index}. {option}")

    choice = input("Enter your choice (number): ")
    try:
        selected_index = int(choice) - 1
        selected = options[selected_index]
        print(f"You selected: {selected}")

        if selected_index == 0:
            process_graphs = True
        elif selected_index == 1:
            process_graphs = False
        elif selected_index == 2:
            process_graphs = True
            process_the_details = False

            # do not prompt for probabibilities or print sampling as they are N/A
            min_probability_of_profit_mc = 0.0
            print_samples = False # I know this line is redundant since earlier I set it to False.
            return min_probability_of_profit_mc, process_graphs, process_the_details, print_samples

    except (IndexError, ValueError):
        print("Invalid selection, please enter a number from the list.")
        return UE_get_feedback_preference()  # Recursively ask again

    # get the user's desired min PoP - filter criteria
    min_probability_of_profit_mc = UE_get_min_POP()

    print(f"{BOLD}\nStep 4 - Choose Your Feedback Preference... this does not affect final output{RESET}\n")
    while True:
        user_input = input("Do you want to print out sample records during long processing times? (Y/N) ").upper()
        if user_input == 'Y':
            print_samples = True
            return min_probability_of_profit_mc, process_graphs, process_the_details, print_samples
        elif user_input == 'N':
            print_samples = False # I know this line isn't necessary
            return min_probability_of_profit_mc, process_graphs, process_the_details, print_samples

        else:
            print("Invalid input. Please enter (Y)es or (N)o.")

def get_UE_inputs():
    """ get all the user inputs; also allow user to rollback decisions

        Returns index_ETF, is_custom, and print_samples
    """

    print_samples = False
    process_graphs = False
    process_the_details = False
    min_probability_of_profit_mc = 0.0

    # get the user's desired stock holdings -  filter criteria
    index_etf, is_custom = UE_choose_stock_index_etf()

    # get the user's preference for feedback during long processing periods
    min_probability_of_profit_mc, process_graphs, process_the_details, print_samples = UE_get_feedback_preference()

    continue_on = input("Go back / change anything? (Y/N): ").upper()
    if continue_on == "Y":
        print("Restarting...")
        return get_UE_inputs()
    else:
        print("\n") # break up the next print statements on the console
        return is_custom, index_etf, process_graphs, process_the_details, print_samples, min_probability_of_profit_mc

def get_holdings(symbol_list: str):
    """ Scrape through Zacks for ETF or index stock holdings """
    symbol_list = symbol_list.upper()
    if symbol_list == '*MAGNIFICENT 7':
        # "Magnificent 7" is a reserve word of stocks-- not an index per se
        stock_data = ['AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'TSLA' ]
        return stock_data

    # *TOP 31 BUZZ - Part I', '*TOP 31 BUZZ - Part II', '*TOP 31 BUZZ - All'
    if symbol_list == '*TOP 31 BUZZ - PART I':
        # "Top 31 Buzz" is a reserve word of stocks-- not an index per se
        stock_data = ['AAPL', 'ABNB', 'AMZN', 'ASML', 'AVGO', 'CCL',
                      'CGC', 'COIN', 'CMG', 'COST', 'CRWD', 'DBX',
                      'GOOGL', 'GME', 'META', 'MRK'] # partial list (Part 1) Can't run 25+ stocks at a time
        return stock_data

    if symbol_list == '*TOP 31 BUZZ - PART II':
        # "Top 31 Buzz" is a reserve word of stocks-- not an index per se
        stock_data = ['MSFT', 'NFLX', 'QCOM', 'SBUX', 'SMCI', 'SNAP',
                      'SPOT', 'SQ', 'TQQQ', 'TSLA', 'TSM', 'UBER',
                      'USD', 'NVDA', 'NU' ] # partial list (Part 2)
        return stock_data

    if symbol_list == '*TOP 31 BUZZ - ALL':
        # "Top 31 Buzz" is a reserve word of stocks-- not an index per se
        stock_data = ['AAPL', 'ABNB', 'AMZN', 'ASML', 'AVGO', 'CCL',
                      'CGC', 'COIN', 'CMG', 'COST', 'CRWD', 'DBX',
                      'GOOGL', 'GME', 'META', 'MRK', 'MSFT', 'NFLX',
                      'NVDA', 'NU', 'QCOM', 'SBUX', 'SMCI', 'SNAP',
                      'SPOT', 'SQ', 'TQQQ', 'TSLA', 'TSM', 'UBER',
                      'USD'] # full list
        return stock_data

    # process an existing ETF or Index
    stock_url = 'https://www.zacks.com/funds/etf/{}/holding'
    # this is the website we will scrap stock holdings from

    stock_data = []
    browser_headers = {
          "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0"
    }

    with requests.Session() as req:
        req.headers.update(browser_headers)
        r = req.get(stock_url.format(symbol_list))
        print(f"Extracting stock data from... {r.url}")

        goal = re.findall(r'etf\\\/(.*?)\\', r.text)
        stock_data.append(goal)
    return goal

def get_stock_price(ticker):
    try:
        stock = yf.Ticker(ticker)
        current_price = stock.history(period="1d")["Close"].iloc[-1]
        return current_price
    except:
        return None

import yfinance as yf

def get_stock_name(ticker_symbol):

    """ Example usage
    ticker_symbol = 'AAPL'  # Apple Inc.
    name = get_stock_name(ticker_symbol)
    print(f"The company name for ticker '{ticker_symbol}' is: {name}")
    """

    # Create a Ticker object
    stock = yf.Ticker(ticker_symbol)

    # Fetch stock info
    stock_info = stock.info

    # Retrieve the company name
    company_name = stock_info.get('longName')

    return company_name

def get_option_expirations(ticker):
    try:
        stock = yf.Ticker(ticker)
        expirations = stock.options
        return expirations
    except:
        return []

def get_option_chain(ticker, expiration_date):
    try:
        stock = yf.Ticker(ticker)
        option_chain = stock.option_chain(expiration_date)
        return option_chain
    except:
        return None

def calculate_iv_rank(current_iv, historical_ivs):
    """
    Calculate the IV Rank for the current implied volatility.

    Parameters:
    current_iv (float): The current implied volatility.
    historical_ivs (list): A list of historical implied volatility values.

    Returns:
    tuple: The IV Rank as a float and the cost factor as a string.

    min_iv = 0.0010000000000000002. max_iv = 300.00025. current_iv = 0.0010000000000000002. iv_rank = 0.0
    = ((0.0010000000000000002 - 0.0010000000000000002) / (300.00025 - 0.0010000000000000002))

    """
    min_iv = min(historical_ivs)
    max_iv = max(historical_ivs)

    if max_iv == min_iv:
        iv_rank = 0
    else:
        iv_rank = ((current_iv - min_iv) / (max_iv - min_iv))

    if iv_rank <= 1.0:
        iv_rank = iv_rank * 100 # account for a decimal

    if iv_rank >= HIGH_IV:
        cost_factor = "EXPENSIVE"
    elif iv_rank > LOW_IV:
        cost_factor = "MODERATELY PRICED"
    else:
        cost_factor = "INEXPENSIVE"

    return iv_rank, cost_factor

def format_iv_rank(iv_rank, cost_factor):
    """
    Format the IV rank with color based on its category.

    Parameters:
    iv_rank (float): The calculated IV rank.
    cost_factor (str): The categorization of the cost.
    """
    if cost_factor == "EXPENSIVE":
        color = RED
    elif cost_factor == "MODERATELY PRICED":
        color = BLUE
    else:
        color = GREEN

    return f"{BOLD}{color}{iv_rank:.2f}% {cost_factor}{RESET}"

def get_closest_strike_prices(option_type, option_chain, current_price, num_strike_prices=50):
    """ Returns all the strike prices associated with the option chain

        Arguments
        option_type (string):   "Call" or "Put"
        option_chain (list):    option chain information including strike prices
        current_price (float):  current stock price
        num_strike_prices (int): number of closest strike prices to return

        Returns
        closest_strike_prices (list): list of closest strike prices
    """

    if option_type.upper() == "CALL":
        strike_prices_calls = option_chain.calls['strike']
        closest_strike_prices = sorted(strike_prices_calls, key=lambda x: abs(x - current_price))[:num_strike_prices]
    else:
        strike_prices_puts = option_chain.puts['strike']
        closest_strike_prices = sorted(strike_prices_puts, key=lambda x: abs(x - current_price))[:num_strike_prices]
    return closest_strike_prices

def format_with_colors_for_numeric_values (value):
    """ color code minus numbers as red; positive numbers as green; 0 as neutral
    """
    if value < 0:
      color = RED
    elif value > 0:
      color = GREEN
    else:
      color = RESET  # or some default color/formatting for zero change

    return f"{BOLD}{UNDERLINE}{color}{value:.2f}%{RESET}"

def format_with_colors_for_Boolean_values (value):
    """ color code True as Green; False as Red """
    color = RED
    if value:
      color = GREEN

    return f"{BOLD}{color}{value}{RESET}"

def capture_stdout(func, *args, **kwargs):
    """
    Capture the output of a method so that it does not output to screen/console.

    Parameters:
        func (callable): The function to capture output from.
        *args: Positional arguments to pass to the function.
        **kwargs: Keyword arguments to pass to the function.

    Returns:
        str: Captured output as a string, or an error message if an exception occurs.
    """

    old_stdout = sys.stdout
    new_stdout = StringIO()
    sys.stdout = new_stdout
    try:
        func(*args, **kwargs)
    except Exception as e:
        error_message = f"Error occurred: {e}"
        print(error_message)  # Optionally, log this error or handle it as needed
        return error_message
    finally:
        sys.stdout = old_stdout
    return new_stdout.getvalue()

def aggregate_profiling_stats(profiling_output):
    """
    Aggregate profiling statistics for each function and format the output.

    Parameters:
        profiling_output (str): Profiling statistics output captured from LineProfiler.

    Returns:
        str: Formatted aggregated statistics.
    """
    aggregated_stats = {}
    current_function = None

    lines = profiling_output.strip().split('\n')
    for line in lines:
        if line.startswith('Total time'):
            total_time_line = line.split(':')
            if current_function:
                aggregated_stats[current_function]['total_time'] = float(total_time_line[1].strip().split()[0])
        elif line.startswith('File:'):
            file_line = line.split(':')
            function_line = next(lines)  # Assuming the next line is the function definition
            function_name = function_line.split(' ')[-2]
            current_function = f"{function_name} in {file_line[1].strip()}"
            aggregated_stats[current_function] = {}
        elif line.startswith('Line #'):
            pass  # Skip line details, you may adjust if needed

    formatted_output = []
    for function, stats in aggregated_stats.items():
        total_time = stats.get('total_time', 0.0)
        formatted_output.append(f"{function}\nTotal time: {total_time:.1f} s\n")

    return '\n'.join(formatted_output)

def setup_for_output():
    data =  [
              {
                  'Company Name & Ticker': None,
                  'Contract Symbol': None,
                  'Option Type': None,
                  'Strike Price': None,
                  'Days Until Expiration': None,
                  'Probability of Profit LSM': None,
                  'Probability of Profit MC': None,
                  'Probability of Profit BSM': None,
                  'IV Rank (calculated)': None,
                  'IV Rank II (yfinance)': None,
                  'Bid': None,
                  'Ask': None,
                  'Last Price': None,
                  'Breakeven Price (Range)': None,
                  'Breakeven In the Money': None,
                  'Underlying Stock Price' : None,
                  'In the Money': None,
                  'Implied Volatility (calculated)': None,
                  'Implied Volatility II (yfinance)': None,
                  'Volume': None,
                  'Open Interest': None,
                  'Change': None,
                  'Percent Change': None,
                  'Delta': None,
                  'Gamma': None,
                  'Theta': None,
                  'Vega': None,
                  'Expiration Date': None
             }
            ]
    return data

def upload_image_to_drive(filename, drive_service, new_width, new_height):
    from PIL import Image
    from io import BytesIO
    from googleapiclient.http import MediaIoBaseUpload

    # Define the function to resize the image
    def resize_image(filename, new_width, new_height):
        image = Image.open(filename)
        resized_image = image.resize((new_width, new_height))
        output = BytesIO()
        resized_image.save(output, format='PNG')
        output.seek(0)
        return output

    # Resize the image
    resized_image_data = resize_image(filename, new_width, new_height)

    # Upload the resized image data to Google Drive
    file_metadata = {'name': filename}
    media = MediaIoBaseUpload(resized_image_data, mimetype='image/png')
    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()
    file_id = file.get('id')

    # Make the file publicly accessible
    drive_service.permissions().create(
        fileId=file_id,
        body={'type': 'anyone', 'role': 'reader'},
        fields='id',
    ).execute()

    return file_id

def insert_image_in_docs(doc_id, image_id, docs_service, index, width, height):
    """
    Insert an image into a Google Docs document at the specified index.

    Arguments:
        doc_id (str): The ID of the Google Docs document.
        image_id (str): The ID of the image file to insert.
        docs_service (googleapiclient.discovery.Resource): The Google Docs API service.
        index (int): The index at which to insert the image.
        width (int): The width of the image in points. (72 points = 1 inch)
        height (int): The height of the image in points.

    Returns:
        None
    """
    requests = [
        {
            'insertInlineImage': {
                'location': {
                    'index': index,
                },
                'uri': f'https://drive.google.com/uc?id={image_id}',
                'objectSize': {
                    'height': {
                        'magnitude': height,
                        'unit': 'PT'
                    },
                    'width': {
                        'magnitude': width,
                        'unit': 'PT'
                    }
                }
            }
        }
    ]
    docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()

def scrape_financial_ratios_morningstar(ticker):
    """
    Scrapes EPS, PE, and PEG ratios for a given stock ticker from Morningstar.

    Args:
        ticker (str): The stock ticker symbol.

    Returns:
        tuple: A tuple containing EPS, PE ratio, and PEG ratio. If data is not available, returns (None, None, None).

    Raises:
        Exception: If there is an error retrieving the data from Morningstar.
    """
    try:
        # Initialize Morningstar Direct session (replace with your credentials)
        morningstar_data.set_user_credentials("your_username", "your_password")

        # Define the data points you need
        data_points = ["Earnings Per Share", "Price to Earnings", "PEG Ratio"]

        # Fetch the investment data
        investment_data = get_investment_data([ticker], data_points)

        # Parse the data into a DataFrame
        df = pd.DataFrame(investment_data)

        # Extract the required values
        eps = df[df['Data Point'] == 'Earnings Per Share']['Value'].values[0]
        pe = df[df['Data Point'] == 'Price to Earnings']['Value'].values[0]
        peg = df[df['Data Point'] == 'PEG Ratio']['Value'].values[0]

        return eps, pe, peg

    except Exception as e:
        print(f"Error retrieving data from Morningstar for {ticker}: {e}")
        return None, None, None

def get_earnings_performance(ticker):
    """
    Retrieves the earnings performance data for a given stock ticker.

    Args:
        ticker (str): The stock ticker symbol.

    Returns:
        pandas.DataFrame: A DataFrame containing earnings performance data with columns:
                          'Earnings Date', 'Avg Perf Before Earnings', 'Avg Perf At Earnings', 'Avg Perf After Earnings',
                          'EPS', 'PE Ratio', 'PEG Ratio'.

    Raises:
        KeyError: If an earnings date does not exist in the historical data.
    """
    stock = yf.Ticker(ticker)
    earnings_dates = stock.earnings_dates.index.tolist()[-12:]

    performance_data = []

    for date in earnings_dates:
        earnings_date = pd.to_datetime(date)

        # Determine the quarter
        quarter = (earnings_date.month - 1) // 3 + 1

        # Define the date ranges
        two_weeks_before = earnings_date - timedelta(days=14)
        one_day_after = earnings_date + timedelta(days=1)
        two_weeks_after = earnings_date + timedelta(days=14)

        # Fetch historical stock data
        hist = stock.history(start=two_weeks_before - timedelta(days=1), end=two_weeks_after + timedelta(days=1))

        # Calculate performance
        before_perf = (hist.loc[two_weeks_before:earnings_date].pct_change().mean() * 100)
        at_perf = (hist.loc[earnings_date:one_day_after].pct_change().mean() * 100)
        after_perf = (hist.loc[earnings_date:two_weeks_after].pct_change().mean() * 100)

        # Scrape PE and PEG ratios from Morningstar
        eps, pe_ratio, peg_ratio = scrape_financial_ratios_morningstar(ticker)

        performance_data.append({
            'Quarter': quarter,
            'Before': before_perf,
            'At': at_perf,
            'After': after_perf,
            'EPS': eps,
            'PE Ratio': pe_ratio,
            'PEG Ratio': peg_ratio
        })

    return pd.DataFrame(performance_data)

def plot_earnings_performance(df):
    # Convert relevant columns to numeric, coerce errors to NaN
    df['Quarter'] = pd.to_numeric(df['Quarter'], errors='coerce')
    for period in ['Before', 'At', 'After']:
        df[period] = pd.to_numeric(df[period], errors='coerce')

    # Drop rows with NaN values in the relevant columns
    df.dropna(subset=['Quarter', 'Before', 'At', 'After'], inplace=True)

    # Average performance per quarter
    avg_perf = df.groupby('Quarter').mean()

    # Ensure we have all quarters
    quarters = ['Q1', 'Q2', 'Q3', 'Q4']
    for quarter in quarters:
        if quarter not in avg_perf.index:
            avg_perf.loc[quarter] = [np.nan] * len(avg_perf.columns)

    avg_perf = avg_perf.loc[quarters]  # Reorder to ensure correct order

    periods = ['Before', 'At', 'After']
    x = np.arange(len(quarters))

    fig, ax = plt.subplots(figsize=(10, 6))

    for period in periods:
        if period in avg_perf.columns:
            ax.plot(quarters, avg_perf[period], marker='o', label=period)

    ax.axhline(0, color='gray', linewidth=0.8, linestyle='--')
    ax.set_xlabel('Quarters')
    ax.set_ylabel('Average Performance (%)')
    ax.set_title('Stock Performance Around Earnings')
    ax.legend()

    # Adding diamonds for earnings dates
    for i in range(len(quarters)):
        ax.plot(x[i], 0, 'D', color='red')

    plt.show()

def get_financial_ratios(ticker):
    """
    xxx - not done

    Retrieves EPS, PE, and PEG ratios for a given stock ticker from Morningstar.

    Args:
        ticker (str): The stock ticker symbol.

    Returns:
        dict: A dictionary containing EPS, PE, and PEG ratios.

    Example Usage:
        ticker = "AAPL"
        financial_ratios = get_financial_ratios(ticker)
        if financial_ratios:
            print(f"Financial Ratios for {ticker}:")
            print(f"EPS: {financial_ratios['EPS']}")
            print(f"PE Ratio: {financial_ratios['PE Ratio']}")
            print(f"PEG Ratio: {financial_ratios['PEG Ratio']}")
        else:
            print("Failed to retrieve financial ratios.")
    """
    try:
        # Initialize Morningstar Direct session (replace with your credentials)
        morningstar_data.set_user_credentials("your_username", "your_password")

        # Define the data points you need
        data_points = ["Earnings Per Share", "Price to Earnings", "PEG Ratio"]

        # Fetch the investment data
        investment_data = get_investment_data([ticker], data_points)

        # Parse the data into a DataFrame
        df = pd.DataFrame(investment_data)

        # Extract the required values
        eps = df[df['Data Point'] == 'Earnings Per Share']['Value'].values[0]
        pe = df[df['Data Point'] == 'Price to Earnings']['Value'].values[0]
        peg = df[df['Data Point'] == 'PEG Ratio']['Value'].values[0]

        return {
            'EPS': eps,
            'PE Ratio': pe,
            'PEG Ratio': peg
        }

    except Exception as e:
        print(f"Error retrieving data: {e}")
        return None

def calculate_mfi(data, window=14):
    """
    Calculates the Money Flow Index (MFI) using high, low, and close prices along with volume.

    Args:
        data (pandas.DataFrame): The stock price data with columns 'High', 'Low', 'Close', and 'Volume'.
        window (int): The window size for calculating the MFI.

    Returns:
        pandas.Series: The MFI values.
    """

    typical_price = (data['High'] + data['Low'] + data['Close']) / 3
    money_flow = typical_price * data['Volume']

    positive_flow = money_flow.where(typical_price > typical_price.shift(1), 0).fillna(0)
    negative_flow = money_flow.where(typical_price < typical_price.shift(1), 0).fillna(0)

    positive_flow_sum = positive_flow.rolling(window=window, min_periods=1).sum()
    negative_flow_sum = negative_flow.rolling(window=window, min_periods=1).sum()

    money_flow_ratio = positive_flow_sum / negative_flow_sum
    mfi = 100 - (100 / (1 + money_flow_ratio))

    return mfi

def calculate_rsi(prices, window=14):
    """
    Calculates the Relative Strength Index (RSI) using vectorized operations.

    Args:
        prices (pandas.Series): A series of prices.
        window (int): The window size for calculating the RSI.

    Returns:
        pandas.Series: The RSI values.
    """
    delta = prices.diff(1)
    gain = (delta.where(delta > 0, 0)).fillna(0)
    loss = (-delta.where(delta < 0, 0)).fillna(0)

    avg_gain = gain.rolling(window=window, min_periods=1).mean()
    avg_loss = loss.rolling(window=window, min_periods=1).mean()

    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    return rsi

def calculate_stochastic_oscillator(graph_data, window=14):
    """
    Calculates Stochastic Oscillator values (K and D) for the given stock price data.

    Args:
        graph_data (pandas.DataFrame): The stock price data.
        window (int): The window period for calculation (default is 14).

    Returns:
        pandas.Series: The Stochastic Oscillator K values.
        pandas.Series: The Stochastic Oscillator D values.
    """
    if 'Low' not in graph_data.columns or 'High' not in graph_data.columns or 'Adj Close' not in graph_data.columns:
        raise ValueError("Required columns (Low, High, Adj Close) not found in graph_data.")

    lowest_low = graph_data['Low'].rolling(window=window).min()
    highest_high = graph_data['High'].rolling(window=window).max()

    # Calculate Stochastic Oscillator K
    graph_data['Stochastic_Oscillator_K'] = 100 * ((graph_data['Adj Close'] - lowest_low) / (highest_high - lowest_low))

    # Calculate Stochastic Oscillator D (Simple Moving Average of K)
    graph_data['Stochastic_Oscillator_D'] = graph_data['Stochastic_Oscillator_K'].rolling(window=3).mean()

    return graph_data['Stochastic_Oscillator_K'], graph_data['Stochastic_Oscillator_D']

def add_technical_indicators(graph_data):
    """
    Adds technical indicators (SMA, RSI, MFI, and Stochastic Oscillator) to the stock price data.

    Args:
        graph_data (pandas.DataFrame): The stock price data.

    Returns:
        pandas.DataFrame: The stock price data with added indicators.
    """
    if graph_data is None:
        return None

    graph_data['SMA_50'] = graph_data['Adj Close'].rolling(window=50).mean()
    graph_data['SMA_100'] = graph_data['Adj Close'].rolling(window=100).mean()
    graph_data['RSI'] = calculate_rsi(graph_data['Adj Close'], window=14)
    graph_data['MFI'] = calculate_mfi(graph_data, window=14)
    graph_data['Stochastic_Oscillator_K'], graph_data['Stochastic_Oscillator_D'] = calculate_stochastic_oscillator(graph_data, window=14)

    return graph_data

def save_and_close_plot(filename, fig):
    """
    Saves the plot to a file and closes the figure to free up memory.

    Args:
        filename (str): The filename to save the plot as.
        fig (matplotlib.figure.Figure): The figure to save and close.
    """
    fig.savefig(filename, dpi=300, bbox_inches='tight')
    plt.close(fig)

def plot_first_set_of_charts(graph_data, filename, chart_title_prefix):
    """
    Plots stock analysis including stock prices, moving averages, RSI, MFI,
      Bollinger Bands, and Stochastic Oscillator... across two images.

      Two images enable the images to span two pages and be formatted using
        the appropriate space, including the entire second page (almost...)

    Args:
        graph_data (pandas.DataFrame): The stock price data with technical indicators.
        filename (str): The filename to save the plot as.
        chart_title_prefix (str): The prefix for the chart titles.
    """
    fig, axs = plt.subplots(2, 1, figsize=(11, 8.5), dpi=1200)  # 2 charts in one figure

    legend_size = 10
    label_size = 10
    title_size = 14

    # Plot 1: Moving Averages and Closing Price
    axs[0].plot(graph_data.index, graph_data['Adj Close'], label='Closing Price', linewidth=1.5)
    axs[0].plot(graph_data.index, graph_data['SMA_50'], label='50-day SMA', linewidth=1.5)
    axs[0].plot(graph_data.index, graph_data['SMA_100'], label='100-day SMA', linewidth=1.5)
    axs[0].set_title(f'{chart_title_prefix} Stock Prices & Moving Averages', fontsize=title_size)
    axs[0].legend(fontsize=legend_size)
    axs[0].tick_params(axis='both', which='major', labelsize=label_size)

    # Plot 2: RSI
    axs[1].plot(graph_data.index, graph_data['RSI'], label='Relative Strength Index', linewidth=1.5)
    axs[1].axhline(y=35, color='r', linestyle='-', linewidth=1)
    axs[1].axhline(y=70, color='g', linestyle='-', linewidth=1)
    axs[1].set_title(f'{chart_title_prefix} Relative Strength Index', fontsize=title_size)
    axs[1].legend(fontsize=legend_size)
    axs[1].tick_params(axis='both', which='major', labelsize=label_size)

    plt.tight_layout()
    save_and_close_plot(filename, fig)

def plot_remaining_charts(graph_data, filename, chart_title_prefix):
    """
    Plots stock analysis including stock prices, moving averages, RSI, MFI,
      Bollinger Bands, and Stochastic Oscillator... across two images.

      Two images enable the images to span two pages and be formatted using
        the appropriate space, including the entire second page (almost...)

    Args:
        graph_data (pandas.DataFrame): The stock price data with technical indicators.
        filename (str): The filename to save the plot as.
        chart_title_prefix (str): The prefix for the chart titles.

    Special Note: this method and the one before it "plot_first_set..." could
        be refactored to reuse a lot of the lines (e.g., ax.plot....['Close']...)
    """
    fig, axs = plt.subplots(3, 1, figsize=(11, 8.5), dpi=1200)  # 3 charts in one figure

    legend_size = 10
    label_size = 10
    title_size = 14

    # Plot 3: MFI
    axs[0].plot(graph_data.index, graph_data['MFI'], label='Money Flow Index', color='purple', linewidth=1.5)
    axs[0].axhline(y=20, color='r', linestyle='-', linewidth=1)
    axs[0].axhline(y=80, color='g', linestyle='-', linewidth=1)
    axs[0].set_title(f'{chart_title_prefix} Money Flow Index', fontsize=title_size)
    axs[0].legend(fontsize=legend_size)
    axs[0].tick_params(axis='both', which='major', labelsize=label_size)

    # Plot 4: Bollinger Bands
    axs[1].plot(graph_data.index, graph_data['Close'], label='Closing Prices', color='blue', linewidth=1.5)
    axs[1].plot(graph_data.index, graph_data['Upper Band'], label='Upper Bollinger Band', color='red', linewidth=1.5)
    axs[1].plot(graph_data.index, graph_data['Middle Band'], label='Middle Bollinger Band', color='green', linewidth=1.5)
    axs[1].plot(graph_data.index, graph_data['Lower Band'], label='Lower Bollinger Band', color='red', linewidth=1.5)
    axs[1].fill_between(graph_data.index, graph_data['Lower Band'], graph_data['Upper Band'], color='red', alpha=0.1)
    axs[1].set_title(f'{chart_title_prefix} Bollinger Bands', fontsize=title_size)
    axs[1].legend(fontsize=legend_size)
    axs[1].tick_params(axis='both', which='major', labelsize=label_size)

    # Plot 5: Stochastic Oscillator
    axs[2].plot(graph_data.index, graph_data['Stochastic_Oscillator_K'], label='Stochastic Oscillator K', color='orange', linewidth=1.5)
    axs[2].plot(graph_data.index, graph_data['Stochastic_Oscillator_D'], label='Stochastic Oscillator D', color='purple', linewidth=1.5)
    axs[2].axhline(y=20, color='r', linestyle='-', linewidth=1)
    axs[2].axhline(y=80, color='g', linestyle='-', linewidth=1)
    axs[2].set_title(f'{chart_title_prefix} Stochastic Oscillator', fontsize=title_size)
    axs[2].legend(fontsize=legend_size)
    axs[2].tick_params(axis='both', which='major', labelsize=label_size)

    plt.tight_layout()
    save_and_close_plot(filename, fig)

def calculate_bollinger_bands(data, window=20, num_std=2):
    """
    Calculates Bollinger Bands and adds them to the stock price data.

    Args:
        data (pandas.DataFrame): The stock price data.
        window (int): The window size for calculating the moving average.
        num_std (int): The number of standard deviations for the bands.

    Returns:
        pandas.DataFrame: The stock price data with Bollinger Bands.
    """
    if data is not None:
        data['Middle Band'] = data['Close'].rolling(window=window).mean()
        std = data['Close'].rolling(window=window).std()
        data['Upper Band'] = data['Middle Band'] + (std * num_std)
        data['Lower Band'] = data['Middle Band'] - (std * num_std)
    return data

def get_technical_analysis(ticker, company_ticker, doc_service, doc_id,
                           image_file_id_list, current_line_number,
                           process_the_details):
    """
    Retrieves stock data, calculates technical indicators, and plots analysis.

    Args:
        ticker (str): The stock ticker symbol.
        company_ticker (str): The company ticker symbol.
        doc_service (googleapiclient.discovery.Resource): The Google Docs API service.
        doc_id (str): The Google Docs document ID.
        image_file_id_list (list): A list to store uploaded image file IDs.
        current_line_number (int): The current line number in the Google Docs document.
    """
    global TODAY
    global BLUE_COLOR

    start_date = TODAY - timedelta(days=396)  # 1 yr + 1 month (13 months) of data
    graph_data = yf.download(ticker, start=start_date, end=TODAY, progress=False)

    """
    doc_title = (
        f"{company_ticker} Technical Analysis: "
        f"    Stock Price = ${current_price:.2f}\n"
    )
    current_line_number = write_text_to_Google_doc(
                              doc_service, doc_id, doc_title, bold=True,
                              color=BLUE_COLOR)
    # I don't think the above lines add value to the document.
    # Also, I can eliminate arguments passed to this method (e.g., current_price)
    """

    if graph_data is not None:
        graph_data = add_technical_indicators(graph_data)

        if graph_data is not None:
            graph_data = calculate_bollinger_bands(graph_data)
        else:
            print("Data was None after adding indicators.")
    else:
        print("Failed to download data.")

    width = 702 # x / 72 = 9.75 inches
    height = 486 # x / 72 = 6.75 inches
    current_line_number -= 1 # decrement by 1

    drive_service = build('drive', 'v3', credentials=GoogleCredentials.get_application_default())

    # Plot and save the first two charts
    text_to_append = "Chart 1 of 2"
    current_line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=False, color=BLUE_COLOR, page_break=True) # page break after the chart

    filename1 = f"{company_ticker}_technical_analysis_part1.png"
    plot_first_set_of_charts(graph_data, filename1, company_ticker)
    image_id1 = upload_image_to_drive(filename1, drive_service, width, height)  # Adjust dimensions if needed
    image_file_id_list.append(image_id1)
    insert_image_in_docs(doc_id, image_id1, doc_service, current_line_number, width, height)  # Adjust dimensions if needed

    # Plot and save the remaining charts
    text_to_append = "Chart 2 of 2"
    current_line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=False, color=BLUE_COLOR, page_break=True) # page break after the  chart

    filename2 = f"{company_ticker}_technical_analysis_part2.png"
    plot_remaining_charts(graph_data, filename2, company_ticker)
    image_id2 = upload_image_to_drive(filename2, drive_service, width, height)  # Adjust dimensions if needed
    image_file_id_list.append(image_id2)
    insert_image_in_docs(doc_id, image_id2, doc_service, current_line_number, width, height)  # Adjust dimensions if needed

    return None

def print_high_probability_target(PoP_print, print_samples, company_ticker, option_type, closest_strike,
                                  stock_price, breakeven_price_range_print, formatted_expiration_date):
    """
    Prints a formatted string with details about a high probability target option trade.

    Args:
        PoP_print (float): The chosen probability of profit (PoP) for the option trade => could be MC, BSM, LSM
        print_samples (bool): Whether to print sample records during long processing times.
        company_ticker (str): The ticker symbol of the company for the option trade.
        option_type (str): The type of option (e.g., 'Call' or 'Put').
        closest_strike (float): The strike price closest to the current stock price.]
        stock_price (float): The current stock price.
        breakeven_price_range_print (str): A formatted string representing the breakeven price range.
        formatted_expiration_date (str): The expiration date of the option in a formatted string.
        print_heading (bool, optional): Whether to print the header along with the details. Defaults to True.

    Returns:
        None

    This function prints a formatted string with details about a high probability target option trade.
    It checks if the probability of profit meets a certain threshold (see global var) and if `print_samples` is True.
    If the condition is not met, the function returns without printing anything.

    If the condition is met, the function constructs the header string, the probability of profit string,
    and the details string using f-strings. The probability of profit string is constructed differently
    based on whether the probability is 100% or not, to account for the extra space before the percentage value.

    FINAL NOTE: this runs off of 1 option price model only. Although, I use
                  multiple models for filtering criteria to spreadsheet, only
                  one (1) model is used filtering the options to print to console,

    If `print_heading` is True, the function prints the header followed by the details.
    If `print_heading` is False, the function prints only the details with a leading space.
    """
    global PRINT_HEADING
    global THRESHOLD

    if not (PoP_print >= THRESHOLD and print_samples):
        return

    header = f"{BOLD}{YELLOW}*** High Probability Target *** {GREEN}{company_ticker} {RESET}"
    pop_str = f"{GREEN} [POP={PoP_print:.2f}%]"
    if PoP_print < 100:
        pop_str = f"{GREEN} [POP= {PoP_print:.2f}%]"

    details = (f"{pop_str} [Option Type={option_type:>4}] [Strike={int(closest_strike):4d}] "
                f"[Expiration Date={formatted_expiration_date}] "
                f"[Stock Price=${stock_price:.2f}] "
                f"[Breakeven (Range)={breakeven_price_range_print}]{RESET}")

    if PRINT_HEADING:
        print(f"{header} {details}")
    else:
        number_of_spaces = len(header) + len(details) - 17 # allow for proper identation
        details = details.rjust(number_of_spaces)
        print(f"{details}")
    PRINT_HEADING = False

def process_option_data(option_type, option_data, closest_strike, current_price, company_ticker,
                        expiration_in_days, formatted_expiration_date,min_probability_of_profit_mc,
                        print_samples, run_all_probabilities):
    """
    Process option data for the given option type and expiration date.

    Arguments:
        option_type (str): The type of option ("CALL" or "PUT").
        option_data (pandas.DataFrame): The option data for the given expiration date.
        closest_strike (float): The closest strike price to the current price.
        current_price (float): The current price of the underlying stock.
        company_ticker (str): The company ticker symbol.
        expiration_in_days (int): The number of days until the expiration date
                        this value will be converted to "years" (i.e., /365) as
                        all subsequent functions assume unit is years.
        formatted_expiration_date (str): The formatted expiration date.
        min_probability_of_profit_mc (float): The minimum probability of profit for Monte Carlo simulation.
        heading_counter (int): A counter to keep track of the number of times the function has been called.
        run_all_probabilities (bool): Whether to run all probabilities for the given expiration date.

    Returns:
        dict: A dictionary containing the processed option data.
        None: If the option data is empty or the probability of profit is below the minimum.
    """
    global RISK_FREE_INTEREST_RATE
    global PRINT_HEADING
    global DEBUG_COUNTER

    if option_data.empty:
        return None

    # setup values
    american_style_option = True
    time_in_yrs = expiration_in_days / 365 # I've ensured expiration_in_days >= 1 always
    num_simulations = 10000   # number of scenarios to run to test for PoP.
    price_used = option_data.iloc[0]['ask'] if option_data.iloc[0]['ask'] > option_data.iloc[0]['lastPrice'] else option_data.iloc[0]['lastPrice']

    """   Calculate d1 is used by Black Scholes and all the Greeks;
          As such, I refactored the code to pull it out the d1 calculation to
          have it only be done ONCE

          This includes calculating
            volatility,
            time_in years,
            RISK_FREE_INTEREST_RATE
    """

    # get volatility accurate
    implied_volatility = max(calculate_implied_volatility(option_type,price_used,current_price,closest_strike,formatted_expiration_date),0) # in case IV is negative
    implied_volatility2 = option_data.iloc[0]['impliedVolatility']
    min_volatility = 1e-5  # minimum volatility
    volatility = max(min_volatility, implied_volatility, implied_volatility2) # ensure volatility isn't too low

    d1 = calculate_d1(current_price, closest_strike, time_in_yrs, volatility)
    # done with setup

    """
    The LSM variant of MC is rated as better for American Style Options,
          i.e., can sell before expiration
    However, MC only variant is the most risk adjusted.

    Therefore, I will use (or filter) off of both variants but add a handicap to LSM
    handicap is defined below (usually 18%)

    """
    # PoP for traditional Monte Carlo simulations
    probability_mc =  monte_carlo_probability_of_profit_mc(option_type,
                                                        closest_strike, price_used, current_price,
                                                        volatility, time_in_yrs,
                                                        american_style_option,
                                                        num_simulations)

    # setup for PoP using LSM variant of Monte Carlo simulations (American Style Options)
    handicap_num_simulations = int(num_simulations / 10) # reduce by a factor of 10X
    probability_mc_lsm =  monte_carlo_probability_of_profit_lsm(option_type,
                                                        closest_strike, price_used, current_price,
                                                        volatility, time_in_yrs,
                                                        american_style_option,
                                                        handicap_num_simulations)
    # an unfortunate side effect of having multiple models is I have to run
    # them before accessing if they are *not relevant. If I simplied used 1
    # model as the primary/only filter then I could bypass running other models.

    # Calculate the breakeven price range and determine if further processing is needed

    """ Two checks (filters)
        1. probability_mc >= min_POP or probability_mc_lsm - handicap >= min_POP
        2. breakeven_in_the_money-- with at least 5% above "in the money"

        if true then process option data otherwise quit and go to the next iteration
    """

    handicap = 18 # 18% handicap for LSM
    option_multipier = 1.03 # 3% additional spread before I call it a good trade, i.e., "in the money"
    if option_type == "CALL":
        premium_bid = closest_strike + option_data.iloc[0]['bid']
        premium_ask = closest_strike + price_used
        breakeven_in_the_money = True if (max(premium_bid, premium_ask) * option_multipier) <= current_price else False
    else: # process option_type == "PUT"
        premium_bid = closest_strike - option_data.iloc[0]['bid']
        premium_ask = closest_strike - price_used
        breakeven_in_the_money = True if max(premium_bid, premium_ask) >= (current_price * option_multipier) else False

    if run_all_probabilities:
        # if RUN_ALL... then run for all expiration dates and strikes
        # ie, simply printing out probabilities is the point
        pass
    elif ((probability_mc >= min_probability_of_profit_mc) or ((probability_mc_lsm - handicap) >= min_probability_of_profit_mc)):
        if breakeven_in_the_money:
            pass
        else:
            return None
    else:
        return None

    # setup for Black Scholes simulations
    probability_bsm = black_scholes_probability_of_profit(d1, option_type,
                                                          time_in_yrs,
                                                          volatility)

    # determine if the option is value priced or over-priced
    current_iv = implied_volatility
    current_iv2 = implied_volatility2
    historical_ivs = [x * 1 for x in option_data['impliedVolatility'].tolist()] # used to convett to %

    # Calculate the IV Rank
    iv_rank, cost_factor = calculate_iv_rank(current_iv, historical_ivs)
    iv_rank = format_iv_rank(iv_rank, cost_factor)
    iv_rank2, cost_factor2 = calculate_iv_rank(current_iv2, historical_ivs)
    iv_rank2 = format_iv_rank(iv_rank2, cost_factor2)

    # Calculate the "Greeks"
    delta = calculate_delta(
        d1, option_type, current_price)

    theta = calculate_theta(
        d1, option_type, current_price, closest_strike,
        time_in_yrs, volatility)

    gamma = calculate_gamma(
        d1, current_price, time_in_yrs, volatility)

    vega = calculate_vega (
        d1, current_price, time_in_yrs)

    # all processing for this scenario is complete; start final formatting for output
    tmp_bid = min(premium_bid, premium_ask)
    premium_ask = max(premium_bid, premium_ask)
    breakeven_price_range_print = f"${tmp_bid:.2f} - ${premium_ask:.2f}"
    breakeven_in_the_money = format_with_colors_for_Boolean_values(breakeven_in_the_money)

    """ * Special:  Addressing long processing times, by giving the user
                    feedback along the way...
                    if the user chose feedback ==> print_samples = True
                    if the user chose no feedback ==> print_samples = False
    """
    print_high_probability_target(probability_mc_lsm, print_samples, company_ticker,
                                  option_type, closest_strike, current_price,
                                  breakeven_price_range_print,
                                  formatted_expiration_date)

    probability_mc      = format_with_colors_for_numeric_values(probability_mc)
    probability_mc_lsm  = format_with_colors_for_numeric_values(probability_mc_lsm)
    probability_bsm     = format_with_colors_for_numeric_values(probability_bsm)

    current_price_print = f"${current_price:.2f}"
    change_amount = format_with_colors_for_numeric_values(option_data.iloc[0]['change'])
    change_percent_amount = format_with_colors_for_numeric_values(option_data.iloc[0]['percentChange'])

    in_the_money = format_with_colors_for_Boolean_values(option_data.iloc[0]['inTheMoney'])

    volatility = volatility * 100 # convert to %
    implied_volatility2 = implied_volatility2 * 100 # convert to %

    # Set column widths - 28 columns
    # populate option_row with data
    option_row = {
        'Company Name & Ticker': company_ticker,
        'Contract Symbol':option_data.iloc[0]['contractSymbol'],
        'Option Type': option_type,
        'Strike Price': closest_strike,
        'Days Until Expiration': expiration_in_days,
        'Probability of Profit MC': probability_mc,
        'Probability of Profit LSM': probability_mc_lsm,
        'Probability of Profit BSM': probability_bsm,
        'Bid': f"${option_data.iloc[0]['bid']:.2f}",
        'Ask': f"${option_data.iloc[0]['ask']:.2f}",
        'Last Price': f"${option_data.iloc[0]['lastPrice']:.2f}",
        'Breakeven Price (Range)': breakeven_price_range_print,
        'Breakeven In the Money': breakeven_in_the_money,
        'Underlying Stock Price': current_price_print,
        'Volume': option_data.iloc[0]['volume'],
        'Open Interest': option_data.iloc[0]['openInterest'],
        'Delta': f"{delta:.2f}",
        'Gamma': f"{gamma}%",
        'Theta': f"{theta:.2f}",
        'Vega': f"{vega:.2f}",
        'In the Money': in_the_money,
        'Implied Volatility (calculated)': f"{volatility:.2f}%",
        'Implied Volatility II (yfinance)': f"{implied_volatility2:.2f}%",
        'IV Rank (calculated)': iv_rank,
        'IV Rank II (yfinance)': iv_rank2,
        'Change': change_amount,
        'Percent Change': change_percent_amount,
        'Expiration Date': formatted_expiration_date
              }

    return option_row

def profile_option_processing(data, expiration_dates, ticker, company_ticker, stock_company_name,
                              current_price, doc_service, doc_id, min_probability_of_profit_mc,
                              print_samples, run_all_probabilities):
    """
    Process all the valid expiration dates associated with the stock ticker.

    Arguments:
        data (list): A list to store the processed option data.
        expiration_dates (list): A list of expiration dates for options.
        ticker (str): The stock ticker symbol.
        company_ticker (str): The company name and ticker symbol.
        stock_company_name (str): The company name.
        current_price (float): The current price of the stock.
        doc_service (googleapiclient.discovery.Resource): The Google Docs API service.
        doc_id (str): The Google Docs document ID.
        min_probability_of_profit_mc (float): The minimum probability of profit for Monte Carlo simulation.
        print_samples (bool): Whether to print sample records during long processing times.
        run_all_probabilities (bool): Whether to run all expiration dates and strikes.

    Returns:
        None
    """
    global TODAY
    global FORMATTED_TIME
    global PACIFIC_TZ
    global CURRENT_TIME

    # Define 1:30 PM PST as the close of the market
    one_thirty_pm_pst = PACIFIC_TZ.localize(datetime(CURRENT_TIME.year, CURRENT_TIME.month, CURRENT_TIME.day, 13, 30))

    for date in expiration_dates:

        formatted_expiration_date = format_date(datetime.strptime(date, '%Y-%m-%d'))
        option_chain = get_option_chain(ticker, date)
        if option_chain is None:
            # output to file(s)
            text_to_append = f"Error: Unable to fetch option chain for {formatted_expiration_date}. Skipping."
            line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append)
            continue

        # "date" is a datetime object == the current expiration date
        # Calculate the difference in days
        parsed_date = datetime.strptime(date, '%Y-%m-%d').date()  # Convert to datetime.date
        difference = parsed_date - TODAY  # This will work because both are datetime.date objects
        expiration_in_days = difference.days

        # Compare the current time with 1:30 PM PST (market close);  If after market close then skip any expiration date = today
        if expiration_in_days == 0 and CURRENT_TIME > one_thirty_pm_pst:
            print(f"The current time ({FORMATTED_TIME}) is later than or equal to 1:30 PM PST on {TODAY}.")
            continue
        else:
            expiration_in_days = max(1, expiration_in_days) # default to at least 1 day for same day run

        # get the closest strike prices
        closest_strike_prices_calls           = get_closest_strike_prices("CALL", option_chain, current_price)
        closest_strike_prices_puts            = get_closest_strike_prices("PUT",  option_chain, current_price)

        # Process all the CALLs associated with the current expiration date
        for closest_strike in closest_strike_prices_calls:
            """ I've learned call strike prices could be different
                than put strike prices to my surprise!! May 31, 2024 AT&T strike prices
            """
            call_data = option_chain.calls[option_chain.calls['strike'] == closest_strike]
            call_row = process_option_data("CALL", call_data, closest_strike,
                                           current_price, company_ticker,
                                           expiration_in_days,
                                           formatted_expiration_date,
                                           min_probability_of_profit_mc,
                                           print_samples, run_all_probabilities)
            if call_row is not None:
                data.append(call_row)

        # Process all the PUTs associated with the current expiration date
        for closest_strike in closest_strike_prices_puts:
            put_data = option_chain.puts[option_chain.puts['strike'] == closest_strike]
            put_row = process_option_data("PUT", put_data, closest_strike,
                                          current_price, company_ticker,
                                          expiration_in_days,
                                          formatted_expiration_date,
                                          min_probability_of_profit_mc,
                                          print_samples, run_all_probabilities)
            if put_row is not None:
                data.append(put_row)

"""
def test_scenario(option_type, strike_price, premium_paid, underlying_price,
                  volatility, time_in_years, american, num_simulations):

    global RISK_FREE_INTEREST_RATE

    probability_of_profit = monte_carlo_probability_of_profit_mc(
        option_type, strike_price, premium_paid, underlying_price, volatility,
        time_in_years, american, RISK_FREE_INTEREST_RATE, num_simulations
    )
    print(f"{option_type} Scenario: Probability of Profit: {probability_of_profit:.2f}%\n")
"""

def build_services_for_Google_files(index_etf, min_probability_of_profit_mc,
                                    process_the_details):
    """
    Create the Google files and do some setup for the program.

    Arguments:
        index_etf (str): The ETF or index symbol list.
        min_probability_of_profit_mc (float): The minimum probability of profit for Monte Carlo simulation.
        process_the_details (bool): Whether to print/output the details.

    Returns:
        Numerous doc file setup variables
    """
    global RED_COLOR
    global BLUE_COLOR
    global GREEN_COLOR
    global BOLD
    global RESET

    global TODAY
    global FORMATTED_TIME

    # output to file(s) - Start w/ creating a new document
    formatted_date = format_date(TODAY,"%d-%B-%Y")
    header_filename = f"Options Analysis: Header for {index_etf} (Run date & time: {formatted_date} {FORMATTED_TIME})"
    if process_the_details:
        detail_filename = f"Options Analysis for {index_etf} (Run date: {formatted_date})"
    else:
        # change the name of the spreadsheet file since it's going to be empty
        detail_filename = f"<EMPTY FILE> Options Analysis for {index_etf} (Run date: {formatted_date})"

    doc_service = build('docs', 'v1', credentials=GoogleCredentials.get_application_default())
    doc_id = create_document(doc_service,header_filename)
    sheets_service = build('sheets', 'v4', credentials=GoogleCredentials.get_application_default())
    spreadsheet_id = create_sheet(sheets_service, detail_filename)

    # write the first line to the two documents 1. Google Sheet 2. Google Doc - I'm using two docs for now
    text_to_append = f"Run for {index_etf} on {formatted_date} @ {FORMATTED_TIME}\n"
    line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append)
    text_to_append = f"\n{BOLD}Run for {index_etf} on {formatted_date} @ {FORMATTED_TIME}\n{RESET}"
    print(f"{text_to_append}")

    text_to_append = f"Filter Criteria: Monte Carlo (MC) Simulations Probability of Profit (PoP) >= {min_probability_of_profit_mc:.2f}%\n"
    line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=True)

    return doc_service, doc_id, sheets_service, spreadsheet_id

def output_to_file_summary_and_move_files(data, doc_service, doc_id,
                                          sheets_service, spreadsheet_id,
                                          image_file_id_list, num_columns,
                                          process_the_details, process_graphs):
    """
    Performs DQs
    Outputs the detailed data records to Google Spreadsheet
    Outputs the final tally of information to Google Doc

    Arguments
        data (list): A list to store the processed option data.
        doc_service (googleapiclient.discovery.Resource): The Google Docs API service.
        doc_id (str): The Google Docs document ID.
        sheets_service (googleapiclient.discovery.Resource): The Google Sheets API service.
        spreadsheet_id (str): The Google Sheets spreadsheet ID.
        image_file_id_list (list): A list to store the image file IDs.
        num_columns (int): The number of columns in the Google Sheet.
        process_the_details (bool): Whether to print the details.
        process_graphs (bool): Whether to output the technical analysis & graphs.

    Returns
        None
    """
    global NUM_TOTAL_MESSAGES
    global NUM_WARNING_MESSAGES

    global BOLD
    global RESET
    global GREEN_COLOR
    global RED_COLOR
    global BLUE_COLOR

    if process_the_details:
        if data:
            print(f"\n{BOLD}{GREEN}*** Final Outputing to File ***{RESET}")
            filtered_data = [x for x in data if x['Probability of Profit MC'] is not None]
            filtered_and_sorted_data = sorted(filtered_data, key=lambda x: x['Days Until Expiration'], reverse=False)
            output_length = len(filtered_and_sorted_data)

            range_name = 'Sheet1'  # not sure about whether I should even care about naming the Sheet
            Pass_on = update_or_create_sheet_with_size_and_format(sheets_service, spreadsheet_id, range_name, output_length+1, num_columns)
            if not Pass_on: # error - stop here
                print("Error creating or updating the sheet! Program exiting...")
                return

            # create sheet up to +1 the # of rows
            sheet_data = prepare_sheet_data(filtered_and_sorted_data)
            chunk_size = 250
            write_text_to_Google_sheet_in_chunks(sheets_service, spreadsheet_id, range_name, sheet_data, chunk_size)

            if output_length > 5000:
                print(f"{BOLD}{RED}\nToo large of an output. Writing to file only.{RESET}")
            else:
                from tabulate import tabulate
                print(tabulate(filtered_and_sorted_data, headers='keys', tablefmt='grid'))
        # end of data is not empty

        # Finally, write the summary & performance data to file
        # write Summary Message data to file
        text_to_append = f"*** Final Tally ***\n"
        line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=True, color=BLUE_COLOR, page_break=False)

        warning_pct = 0 if NUM_TOTAL_MESSAGES == 0 else (NUM_WARNING_MESSAGES / NUM_TOTAL_MESSAGES) * 100
        text_to_append = f"Number of warning messages {NUM_WARNING_MESSAGES}. Percentage of warnings: {warning_pct:.2f}%"
        line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=True, color=None, page_break=False)

        text_to_append = f"*** Final Tally ***\n"
        line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=True, color=BLUE_COLOR, page_break=False)

    """ end of process_the_details = True """

    # Move the files to the Python Output folder-- known by it's folder id-- found in its URL
    drive_service = build('drive', 'v3', credentials=GoogleCredentials.get_application_default())

    # Move each image to the target folder-- the image must exist on it's own before it can be added to a Doc
    if process_graphs:
        image_folder_id = '19TyuDt2-PPOnsusba4B-WSTUj6tau6SL'     # You need to know the folder ID beforehand
        for file_id in image_file_id_list:
            move_file_to_folder(drive_service, file_id, image_folder_id)

    # of note: regardless if process_details is True/False and/or
    # if process_graphs is True/False we will still create the spreadsheet and doc file!
    folder_headers_id = '1VaeS554U_aE6V1PgjMnCaXHDlpR1mC38'   # You need to know the folder ID beforehand
    folder_details_id = '1zXManKzRdtZoRhzZLroCymHWM_tIsllX'   # You need to know the folder ID beforehand

    move_file_to_folder(drive_service, doc_id, folder_headers_id) # the doc output which includes images within it
    move_file_to_folder(drive_service, spreadsheet_id, folder_details_id) # spreadsheet output

    return None

def main():
    """ here's the flow of the program:
        User selects an ETF / INDEX "index_etf, is_custom = UE_choose_stock_index_etf()"
        User selects the minimum PoP they will accept as filter criteria
            |
             ___ {get STOCKS (ticker) associated with that ETF/INDEX} "for counter, ticker..."
                      |
                      ___   {print technical analysis charts for ticker}
                            {get OPTION CHAIN [i.e., EXPIRATION DATES] for each STOCK} "for date in expiration_dates:..."
                              |
                              ___ {get STRIKE PRICES for CALLS & PUTS for each EXPIRATION DATE} "for closest_strike in closest_strike_prices_[call or put]:"
                                        |
                                        ___ {Confirm PoP for each OPTION data.CALL & OPTION_data.PUT > user entered PoP minimum}
                                                  print out each record based on SORT criteria
    """
    global PRINT_HEADING
    global TODAY

    global BLUE_COLOR
    global RED_COLOR
    global GREEN_COLOR

    global REMOVE_FROM_ETF

    # Setup up output record; Records that meet criteria will be stored in "data"
    data = setup_for_output()
    num_columns = len(list(data[0].keys())) # list(data[0].keys()) = names of columns, so this counts the number of column names

    # Setup for technical analysis graphs (images)
    image_file_id_list = [] # load all the image file ids here to move those files later

    # ** User-Entered (UE) Values: ** Get all the user defined inputs (e.g., ETF, min PoP)
    is_custom, index_etf, process_graphs, process_the_details, print_samples, min_probability_of_profit_mc = get_UE_inputs()

    # if 0 entered for probabilities threshold then
    # simply run all expiration dates and strike prices;
    # process all the probability regardless
    run_all_probabilities = True if (min_probability_of_profit_mc <= 0.0) else False

    # Build the service --> create Google Doc & Google Sheet files ... and other associated setup
    doc_service, doc_id, sheets_service, spreadsheet_id = build_services_for_Google_files(
                                        index_etf, min_probability_of_profit_mc,
                                        process_the_details)

    if is_custom: # only 1 stock entered
        stock_holdings = [index_etf]
        text_to_append = f"This run only contains one (1) holding; Name = {stock_holdings}\n"

        print(f"{text_to_append}\n")
        line_number = write_text_to_Google_doc(doc_service, doc_id,text_to_append, bold=False, color=None, page_break=True) # do a page break here

    else: # an etf or index was entered
        stock_holdings = get_holdings(index_etf) # returns the holdings within an ETF or index

        text_to_append = f"\nNote: Certain stocks will be removed as they are redundant...\nAs applicable, the following stocks will be excluded {REMOVE_FROM_ETF}"
        print(text_to_append)
        stock_holdings = [stock for stock in stock_holdings if stock not in REMOVE_FROM_ETF] # remove certain stocks from the etf_index

        text_to_append = ', '.join(stock_holdings)
        text_to_append = f"\n   {index_etf} includes the following revised list of holdings: \n{stock_holdings}\n"
        text_to_append = textwrap.fill(text_to_append, width=120) # Wrap the string at every 120 characters

        print(f"{text_to_append}\n")
        line_number = write_text_to_Google_doc(doc_service, doc_id,text_to_append, bold=False, color=None, page_break=True) # do a page break here

    if process_the_details:
        pass
    else: # there's no expiration date info to print so write "<end of page> here"
        text_to_append = f"\n\n <End of page>"
        line_number = write_text_to_Google_doc(doc_service, doc_id,text_to_append, bold=False, color=None, page_break=True) # do a page break here

    # Process every stock associated with the ETF/Index or an individual run
    total_items = len(stock_holdings) # max number of stock symbols

    for counter, ticker in enumerate(stock_holdings, start=1):
        # add counter along with processing through stock holdings/symbols
        current_price = get_stock_price(ticker)

        if current_price:
            pass
        else:
            ValueError = "Error: Invalid ticker symbol or unable to fetch data."

            # output to file(s)
            text_to_append = f"Error: Invalid ticker symbol {ticker} or unable to fetch data."
            line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append)
            continue

        # get the long name of the stock/company but shorten the name
        stock_company_name = truncate_string(get_stock_name(ticker))
        company_ticker = f"{stock_company_name} ({ticker})"

        # Calculate the instrinsic value of the stock - output it to file
        instrinsic_value, result = analyze_stock(ticker, current_price)

        # output to file(s)
        text_to_append =  (f"Run {counter} of {total_items}... [{stock_company_name} | Stock price: "
                          f"${current_price:.2f} | Intrinsic Value: {instrinsic_value:.2f} | "
                          f"Stock is {result}]\n")
        print(f"{text_to_append}")
        line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append, bold=True, color=BLUE_COLOR, page_break=False)

        """ other than current_price and ticker information - everything else
            should process based on ue values, e.g.,
            "process_the_details = True/False"
            "process_graphs = True/False"
            and print_samples = True/False
        """
        if process_the_details:

            PRINT_HEADING = True # will be used later for printing to console

            expiration_dates = get_option_expirations(ticker)
            if expiration_dates:
                pass
            else:
                print(f"INFO: No expiration dates found for the specified ticker symbol: {ticker}.")

                # output to file(s)
                text_to_append = f"INFO: No expiration dates found for the specified ticker symbol: {ticker}."
                line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append) # use defaults for bold and color

                continue

            # Process all the valid expiration dates associated with the stock ticker
            if print_samples:
                pass # no need to give info to the user since we will report out on all "special rate" options
            else:
                text_to_append = f"   Processing option contract analysis for {company_ticker}"
                print(f"{text_to_append}") # giving some feedback to user

            # process the details!
            profile_option_processing(data, expiration_dates, ticker,
                                      company_ticker, stock_company_name,
                                      current_price, doc_service,
                                      doc_id, min_probability_of_profit_mc,
                                      print_samples, run_all_probabilities)
            if print_samples:
                # print an extra new line to separate if potential trades were outputted to console
                print("\n")

        """ end of 'process_details = True' """

        # print technical analysis charts to screen and file - only if user asked for it!
        if process_graphs:
            # Pull in results based on stock performance around earnings announcement
            # Go back a number of years to analyze and plot / GRAPH performance
            # for now, commented out as it doesnt work properly
            """ not ready to run this code - debug
            earnings_performance_data = get_earnings_performance(ticker)
            if earnings_performance_data is None or earnings_performance_data.empty:
                text_to_append = f"\n ** Failed to get earnings performance data. **\n"
                print({text_to_append})
                line_number = write_text_to_Google_doc(doc_service, doc_id, text_to_append)
            else: # we have data!
                plot_earnings_performance(earnings_performance_data)

            """
            get_technical_analysis(ticker, company_ticker, doc_service, doc_id,
                                   image_file_id_list, line_number,
                                   process_the_details)

        text_to_append = f"   Successfully completed run {counter} of {total_items}... [{stock_company_name} stock price: ${current_price:.2f}]\n"
        print(f"{text_to_append}") # this statement applies to processing the details and/or processing technical analysis

    """" end of for loop - going through every ticker symbol """

    """ output to file(s) after successfully processing each run through
        an underlying stock for ALL of its option contracts associated
        with each and EVERY one of its VALID expiration dates

        Pass print_the_details and process_graphs as arguments to output_to_file_summary_and_move_files()
    """
    output_to_file_summary_and_move_files(data, doc_service, doc_id,
                                          sheets_service, spreadsheet_id,
                                          image_file_id_list, num_columns,
                                          process_the_details, process_graphs)

if __name__ == "__main__":
    main()



